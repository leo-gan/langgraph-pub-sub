{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d3e4d3e-1dda-4504-b400-b6b4e3c58030",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T18:59:19.088594Z",
     "iopub.status.busy": "2025-05-10T18:59:19.088015Z",
     "iopub.status.idle": "2025-05-10T18:59:19.096087Z",
     "shell.execute_reply": "2025-05-10T18:59:19.095198Z",
     "shell.execute_reply.started": "2025-05-10T18:59:19.088556Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Optional, Annotated, Set, Dict\n",
    "import operator\n",
    "import uuid\n",
    "\n",
    "# For pretty printing the state (optional)\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "from IPython.display import Image, display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c455713-3fc2-4ada-b3cd-ac4333436d33",
   "metadata": {},
   "source": [
    "# Pub-Sub architecture\n",
    "\n",
    "Okay, short and sweet:\n",
    "\n",
    "1.  **Publishers:** Send messages (events/data) without knowing who receives them.\n",
    "2.  **Subscribers:** Express interest in specific types of messages (topics/channels) without knowing the publishers.\n",
    "3.  **Topics/Channels (or Broker):** An intermediary that filters and routes messages from publishers to interested subscribers.\n",
    "4.  **Decoupling:** The key. Publishers and subscribers are independent and don't need direct knowledge of each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaa9902-91f4-4ec6-808f-338475c13919",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T18:37:15.124724Z",
     "iopub.status.busy": "2025-05-10T18:37:15.124182Z",
     "iopub.status.idle": "2025-05-10T18:37:15.129772Z",
     "shell.execute_reply": "2025-05-10T18:37:15.129236Z",
     "shell.execute_reply.started": "2025-05-10T18:37:15.124679Z"
    }
   },
   "source": [
    "# v1 Failed attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847167d8-ddc8-432f-89e3-2b025a14d683",
   "metadata": {},
   "source": [
    "Okay, let's implement a Pub-Sub (Publish-Subscriber) like architecture using LangGraph.\n",
    "\n",
    "**Core Idea of Pub-Sub in this Context:**\n",
    "\n",
    "In a traditional Pub-Sub system, a publisher sends messages to a topic, and multiple subscribers interested in that topic receive the message, often concurrently and independently.\n",
    "\n",
    "With LangGraph, we can model this by:\n",
    "1.  **Publisher Node:** A node that generates or processes some data (the \"message\").\n",
    "2.  **State Update:** The publisher node updates the shared state with this message.\n",
    "3.  **Subscriber Nodes:** Multiple subsequent nodes in the graph can then access this \"published\" message from the state and perform their own independent processing.\n",
    "\n",
    "While LangGraph's default execution model is sequential (unless using `AsyncLangGraph` with `asyncio` for I/O-bound tasks or more complex configurations), we can still demonstrate the *flow* of information where one piece of data is made available to multiple consumers. The \"subscribers\" will process the message sequentially in this basic example, but they will all act upon the *same* published message.\n",
    "\n",
    "**Key LangGraph Concepts Used:**\n",
    "\n",
    "*   `StateGraph`: To define the graph.\n",
    "*   `TypedDict`: To define the shared state.\n",
    "*   `Annotated[List[str], operator.add]`: To allow nodes to append messages to lists in the state.\n",
    "*   Nodes: Python functions that modify the state.\n",
    "*   Edges: Define the sequence of node execution.\n",
    "*   `END`: A special node to terminate the graph.\n",
    "\n",
    "Let's create the Python code first, which can then be easily pasted into a Jupyter Notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54c92e0-8132-4f5f-b542-88c6c785148c",
   "metadata": {},
   "source": [
    "## Why is it failed?\n",
    "\n",
    "It doesn't look like the pub-sub since we link a publisher and subscribers explicitly. There should not be explicit links between nodes. The subscribers should select messages not because the messages directed to them but because they are subscribed to some message parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "646ee6f3-5bd0-4265-a059-3625393ab6c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T18:59:22.303429Z",
     "iopub.status.busy": "2025-05-10T18:59:22.302914Z",
     "iopub.status.idle": "2025-05-10T18:59:22.310064Z",
     "shell.execute_reply": "2025-05-10T18:59:22.309342Z",
     "shell.execute_reply.started": "2025-05-10T18:59:22.303391Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- 1. Define the State ---\n",
    "# The state will hold the initial event, the published message,\n",
    "# and logs from each subscriber.\n",
    "class PubSubState(TypedDict):\n",
    "    initial_event_id: str\n",
    "    initial_event_payload: dict\n",
    "    published_message: Optional[str]\n",
    "    # We use Annotated with operator.add so that when a node returns a list\n",
    "    # for these keys, it gets appended to the existing list in the state.\n",
    "    subscriber_alpha_log: Annotated[List[str], operator.add]\n",
    "    subscriber_beta_log: Annotated[List[str], operator.add]\n",
    "    subscriber_critical_log: Annotated[List[str], operator.add]\n",
    "    final_summary: Optional[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b4377da-6e69-4dfb-bc61-a2a81958ca99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T18:59:23.062396Z",
     "iopub.status.busy": "2025-05-10T18:59:23.061930Z",
     "iopub.status.idle": "2025-05-10T18:59:23.070975Z",
     "shell.execute_reply": "2025-05-10T18:59:23.070284Z",
     "shell.execute_reply.started": "2025-05-10T18:59:23.062362Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- 2. Define Node Functions ---\n",
    "\n",
    "# Publisher Node\n",
    "def publisher_node(state: PubSubState) -> dict:\n",
    "    \"\"\"\n",
    "    Processes an initial event and \"publishes\" a message by updating the state.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Publisher Node (Event ID: {state['initial_event_id']}) ---\")\n",
    "    event_payload = state[\"initial_event_payload\"]\n",
    "    \n",
    "    # Simulate processing the event\n",
    "    message_content = f\"Processed event: {event_payload.get('data', 'No data')}. Severity: {event_payload.get('severity', 'UNKNOWN')}\"\n",
    "    published_msg = f\"[Published] {message_content}\"\n",
    "    print(f\"Publishing: {published_msg}\")\n",
    "    \n",
    "    return {\n",
    "        \"published_message\": published_msg,\n",
    "        # Initialize logs for subscribers if they are not present (though TypedDict usually handles this)\n",
    "        \"subscriber_alpha_log\": [],\n",
    "        \"subscriber_beta_log\": [],\n",
    "        \"subscriber_critical_log\": []\n",
    "    }\n",
    "\n",
    "# Subscriber Node Alpha\n",
    "def subscriber_alpha_node(state: PubSubState) -> dict:\n",
    "    \"\"\"\n",
    "    Subscribes to the message and performs its action.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Subscriber Alpha Node ---\")\n",
    "    published_message = state[\"published_message\"]\n",
    "    if not published_message:\n",
    "        print(\"No message published yet.\")\n",
    "        return {}\n",
    "        \n",
    "    log_entry = f\"ALPHA: Received and logged: '{published_message}'\"\n",
    "    print(log_entry)\n",
    "    return {\"subscriber_alpha_log\": [log_entry]} # Appends to the list\n",
    "\n",
    "# Subscriber Node Beta\n",
    "def subscriber_beta_node(state: PubSubState) -> dict:\n",
    "    \"\"\"\n",
    "    Another subscriber that processes the message differently.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Subscriber Beta Node ---\")\n",
    "    published_message = state[\"published_message\"]\n",
    "    if not published_message:\n",
    "        print(\"No message published yet.\")\n",
    "        return {}\n",
    "\n",
    "    processed_info = f\"BETA: Analyzed message: '{published_message}'. Action: Sent notification.\"\n",
    "    print(processed_info)\n",
    "    return {\"subscriber_beta_log\": [processed_info]}\n",
    "\n",
    "# Conditional Subscriber Node (e.g., only for critical messages)\n",
    "def subscriber_critical_node(state: PubSubState) -> dict:\n",
    "    \"\"\"\n",
    "    Subscribes only if the message is deemed critical.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Subscriber Critical Node ---\")\n",
    "    published_message = state[\"published_message\"]\n",
    "    event_payload = state[\"initial_event_payload\"]\n",
    "\n",
    "    if not published_message:\n",
    "        print(\"No message published yet.\")\n",
    "        return {}\n",
    "\n",
    "    # Example condition: check severity from original payload\n",
    "    if event_payload.get(\"severity\") == \"CRITICAL\":\n",
    "        log_entry = f\"CRITICAL_HANDLER: ALERT! Critical event processed: '{published_message}'\"\n",
    "        print(log_entry)\n",
    "        return {\"subscriber_critical_log\": [log_entry]}\n",
    "    else:\n",
    "        log_entry = f\"CRITICAL_HANDLER: Message not critical, skipping: '{published_message}'\"\n",
    "        print(log_entry)\n",
    "        return {\"subscriber_critical_log\": [log_entry]} # Log that it skipped\n",
    "\n",
    "\n",
    "# Optional: A node to summarize or finalize\n",
    "def summary_node(state: PubSubState) -> dict:\n",
    "    print(\"\\n--- Summary Node ---\")\n",
    "    # summary = f\"  Event {state['initial_event_id']} processing complete.\\n\"\n",
    "    # summary += f\"  Published: {state['published_message']}\\n\"\n",
    "    # summary += f\"  Alpha Logs: {len(state['subscriber_alpha_log'])} entries\\n\"\n",
    "    # summary += f\"  Beta Logs: {len(state['subscriber_beta_log'])} entries\\n\"\n",
    "    # summary += f\"  Critical Logs: {len(state['subscriber_critical_log'])} entries\"\n",
    "    summary = f\"\"\"  Event {state['initial_event_id']} processing complete.\n",
    "      Published: {state['published_message']}\n",
    "      Alpha Logs: {len(state['subscriber_alpha_log'])} entries\n",
    "      Beta Logs: {len(state['subscriber_beta_log'])} entries\n",
    "      Critical Logs: {len(state['subscriber_critical_log'])} entries\"\"\"\n",
    "    print(summary)\n",
    "    return {\"final_summary\": summary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a4043a1-8721-4aae-ac89-d475c6dcd485",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T18:59:24.214787Z",
     "iopub.status.busy": "2025-05-10T18:59:24.214551Z",
     "iopub.status.idle": "2025-05-10T18:59:24.222503Z",
     "shell.execute_reply": "2025-05-10T18:59:24.221940Z",
     "shell.execute_reply.started": "2025-05-10T18:59:24.214772Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- 3. Define the Graph Workflow ---\n",
    "workflow = StateGraph(PubSubState)\n",
    "\n",
    "# Add nodes to the graph\n",
    "workflow.add_node(\"publisher\", publisher_node)\n",
    "workflow.add_node(\"subscriber_alpha\", subscriber_alpha_node)\n",
    "workflow.add_node(\"subscriber_beta\", subscriber_beta_node)\n",
    "workflow.add_node(\"subscriber_critical\", subscriber_critical_node) # This node will always run\n",
    "workflow.add_node(\"summary\", summary_node)\n",
    "\n",
    "# Set the entry point\n",
    "workflow.set_entry_point(\"publisher\")\n",
    "\n",
    "# Define the edges - this creates a sequential flow for subscribers\n",
    "# Publisher -> Subscriber Alpha -> Subscriber Beta -> Subscriber Critical -> Summary -> END\n",
    "workflow.add_edge(\"publisher\", \"subscriber_alpha\")\n",
    "workflow.add_edge(\"subscriber_alpha\", \"subscriber_beta\")\n",
    "workflow.add_edge(\"subscriber_beta\", \"subscriber_critical\")\n",
    "workflow.add_edge(\"subscriber_critical\", \"summary\")\n",
    "workflow.add_edge(\"summary\", END)\n",
    "\n",
    "# --- 4. Compile the Graph ---\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2c795e-23d2-4d19-9f82-f7e56e07e1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app.get_graph().draw_mermaid_png(max_retries=5, retry_delay=2.0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08bef10-486f-488d-8751-b601e3426ff3",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "1.  **`PubSubState(TypedDict)`**:\n",
    "    *   `initial_event_id`, `initial_event_payload`: Input to the system.\n",
    "    *   `published_message`: This field will store the message produced by the `publisher_node`. All subsequent \"subscriber\" nodes will read from this.\n",
    "    *   `subscriber_alpha_log`, `subscriber_beta_log`, `subscriber_critical_log`: These lists will store log entries from each subscriber. The `Annotated[List[str], operator.add]` tells LangGraph to append to these lists when a node returns a list for that key, rather than overwriting.\n",
    "    *   `final_summary`: To store a summary at the end.\n",
    "\n",
    "2.  **Node Functions (`publisher_node`, `subscriber_alpha_node`, etc.)**:\n",
    "    *   Each function takes the current `state: PubSubState` as input.\n",
    "    *   They perform their logic.\n",
    "    *   They return a dictionary with keys corresponding to fields in `PubSubState` that they want to update.\n",
    "    *   **Publisher (`publisher_node`)**: Simulates processing an event and sets the `published_message`.\n",
    "    *   **Subscribers (`subscriber_alpha_node`, `subscriber_beta_node`, `subscriber_critical_node`)**: Read the `published_message` from the state and add their own logs. The `subscriber_critical_node` demonstrates conditional logic *within* a subscriber based on the event payload.\n",
    "\n",
    "3.  **Graph Workflow (`StateGraph`)**:\n",
    "    *   We add all our nodes.\n",
    "    *   `set_entry_point(\"publisher\")`: The graph starts with the publisher.\n",
    "    *   `add_edge(...)`: We define a sequential flow: `publisher` -> `subscriber_alpha` -> `subscriber_beta` -> `subscriber_critical` -> `summary` -> `END`.\n",
    "        *   This means after `publisher` finishes, `subscriber_alpha` runs. After `subscriber_alpha`, `subscriber_beta` runs, and so on.\n",
    "        *   Crucially, `subscriber_alpha`, `subscriber_beta`, and `subscriber_critical` all have access to the `published_message` that was set by the `publisher_node` because the state is passed along and updated at each step.\n",
    "\n",
    "4.  **Compilation and Execution**:\n",
    "    *   `app = workflow.compile()`: Compiles the graph into a runnable application.\n",
    "    *   `app.stream(input)`: Executes the graph with the given input and streams the output of each node as it executes.\n",
    "    *   `app.invoke(input)`: Executes the graph and returns the final state.\n",
    "\n",
    "**How this mimics Pub-Sub:**\n",
    "\n",
    "*   **Publish:** The `publisher_node` \"publishes\" information by writing it to the shared `published_message` field in the state.\n",
    "*   **Subscribe:** The `subscriber_alpha_node`, `subscriber_beta_node`, and `subscriber_critical_node` \"subscribe\" to this message by reading it from the state in their respective execution steps.\n",
    "*   **Decoupling (Conceptual):** Although the subscribers run sequentially in this simple LangGraph setup, they are logically decoupled in terms of their processing. Subscriber Alpha doesn't need to know about Subscriber Beta's internals, only about the `published_message`.\n",
    "\n",
    "**To make this a Jupyter Notebook:**\n",
    "\n",
    "1.  Create a new Jupyter Notebook.\n",
    "2.  In the first cell, install necessary packages if you haven't already:\n",
    "    ```python\n",
    "    !pip install langchain langgraph langchain_core\n",
    "    ```\n",
    "3.  Then, paste the Python code into subsequent cells. You can break it down:\n",
    "    *   Cell 1: Imports\n",
    "    *   Cell 2: State Definition (`PubSubState`)\n",
    "    *   Cell 3: Node Functions (publisher, subscribers, summary)\n",
    "    *   Cell 4: Graph Workflow Definition and Compilation\n",
    "    *   Cell 5: Running the Graph (with normal and critical events) and printing outputs.\n",
    "\n",
    "This structure provides a clear demonstration of how one node's output (the published message) can be consumed by multiple subsequent nodes, which is the essence of the Pub-Sub data flow pattern, adapted to LangGraph's stateful execution model. For true parallel execution of subscribers, you'd look into `AsyncLangGraph` and design your nodes as `async` functions performing I/O-bound operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c38b165-6068-462a-ad4a-d761fdaaf029",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T21:31:53.519810Z",
     "iopub.status.busy": "2025-05-09T21:31:53.519542Z",
     "iopub.status.idle": "2025-05-09T21:31:53.527592Z",
     "shell.execute_reply": "2025-05-09T21:31:53.527072Z",
     "shell.execute_reply.started": "2025-05-09T21:31:53.519791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running with a NORMAL event ---\n",
      "\n",
      "--- Publisher Node (Event ID: a928c610-7c1b-419c-87ff-1147f1251646) ---\n",
      "Publishing: [Published] Processed event: System nominal. Severity: NORMAL\n",
      "Output from node: publisher\n",
      "\n",
      "--- Subscriber Alpha Node ---\n",
      "ALPHA: Received and logged: '[Published] Processed event: System nominal. Severity: NORMAL'\n",
      "Output from node: subscriber_alpha\n",
      "\n",
      "--- Subscriber Beta Node ---\n",
      "BETA: Analyzed message: '[Published] Processed event: System nominal. Severity: NORMAL'. Action: Sent notification.\n",
      "Output from node: subscriber_beta\n",
      "\n",
      "--- Subscriber Critical Node ---\n",
      "CRITICAL_HANDLER: Message not critical, skipping: '[Published] Processed event: System nominal. Severity: NORMAL'\n",
      "Output from node: subscriber_critical\n",
      "\n",
      "--- Summary Node ---\n",
      "  Event a928c610-7c1b-419c-87ff-1147f1251646 processing complete.\n",
      "      Published: [Published] Processed event: System nominal. Severity: NORMAL\n",
      "      Alpha Logs: 1 entries\n",
      "      Beta Logs: 1 entries\n",
      "      Critical Logs: 1 entries\n",
      "Output from node: summary\n",
      "\n",
      "\n",
      "=== Final State (NORMAL event) ===\n",
      "\n",
      "--- Publisher Node (Event ID: a928c610-7c1b-419c-87ff-1147f1251646) ---\n",
      "Publishing: [Published] Processed event: System nominal. Severity: NORMAL\n",
      "\n",
      "--- Subscriber Alpha Node ---\n",
      "ALPHA: Received and logged: '[Published] Processed event: System nominal. Severity: NORMAL'\n",
      "\n",
      "--- Subscriber Beta Node ---\n",
      "BETA: Analyzed message: '[Published] Processed event: System nominal. Severity: NORMAL'. Action: Sent notification.\n",
      "\n",
      "--- Subscriber Critical Node ---\n",
      "CRITICAL_HANDLER: Message not critical, skipping: '[Published] Processed event: System nominal. Severity: NORMAL'\n",
      "\n",
      "--- Summary Node ---\n",
      "  Event a928c610-7c1b-419c-87ff-1147f1251646 processing complete.\n",
      "      Published: [Published] Processed event: System nominal. Severity: NORMAL\n",
      "      Alpha Logs: 1 entries\n",
      "      Beta Logs: 1 entries\n",
      "      Critical Logs: 1 entries\n",
      "initial_event_id: a928c610-7c1b-419c-87ff-1147f1251646\n",
      "initial_event_payload: {'data': 'System nominal', 'severity': 'NORMAL'}\n",
      "published_message: [Published] Processed event: System nominal. Severity: NORMAL\n",
      "subscriber_alpha_log: [\"ALPHA: Received and logged: '[Published] Processed event: System nominal. Severity: NORMAL'\"]\n",
      "subscriber_beta_log: [\"BETA: Analyzed message: '[Published] Processed event: System nominal. Severity: NORMAL'. Action: Sent notification.\"]\n",
      "subscriber_critical_log: [\"CRITICAL_HANDLER: Message not critical, skipping: '[Published] Processed event: System nominal. Severity: NORMAL'\"]\n",
      "final_summary:   Event a928c610-7c1b-419c-87ff-1147f1251646 processing complete.\n",
      "      Published: [Published] Processed event: System nominal. Severity: NORMAL\n",
      "      Alpha Logs: 1 entries\n",
      "      Beta Logs: 1 entries\n",
      "      Critical Logs: 1 entries\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Run the Graph ---\n",
    "\n",
    "# Helper to pretty print state (optional)\n",
    "def _print_state(state: dict):\n",
    "    print(\"\\n--- Current State ---\")\n",
    "    for k, v in state['values'].items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    print(\"--------------------\")\n",
    "    return state['values']\n",
    "\n",
    "# You can wrap app.stream with this for debugging\n",
    "# app_with_state_print = app.stream | RunnableLambda(_print_state)\n",
    "\n",
    "\n",
    "print(\"--- Running with a NORMAL event ---\")\n",
    "# state = PubSubState(\n",
    "normal_event_id = str(uuid.uuid4())\n",
    "normal_event_input = {\n",
    "  \"initial_event_id\": normal_event_id,\n",
    "  \"initial_event_payload\": {\"data\": \"System nominal\", \"severity\":   \"NORMAL\"}\n",
    "}\n",
    "final_state_normal = None\n",
    "\n",
    "for s in app.stream(normal_event_input):\n",
    "    # s is a dictionary where keys are node names and values are their outputs\n",
    "    print(f\"Output from node: {list(s.keys())[0]}\") \n",
    "    final_state_normal = s[list(s.keys())[0]] # Get the state after the last node\n",
    "\n",
    "print(\"\\n\\n=== Final State (NORMAL event) ===\")\n",
    "if final_state_normal: # final_state_normal will be the output of the last node (summary)\n",
    "    # To get the full state, we'd typically inspect 's' in the loop\n",
    "    # or invoke the graph and get the full final state directly if not streaming.\n",
    "    # For simplicity, let's re-run with invoke to get the full final state.\n",
    "    final_state_normal_full = app.invoke(normal_event_input)\n",
    "    for key, value in final_state_normal_full.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38a74350-2fe5-463d-b98f-90ded9f2a88d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T21:33:35.552157Z",
     "iopub.status.busy": "2025-05-09T21:33:35.551583Z",
     "iopub.status.idle": "2025-05-09T21:33:35.562806Z",
     "shell.execute_reply": "2025-05-09T21:33:35.562262Z",
     "shell.execute_reply.started": "2025-05-09T21:33:35.552105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Running with a CRITICAL event ---\n",
      "\n",
      "--- Publisher Node (Event ID: 90ea04b5-2005-4be7-a028-eb91f049e478) ---\n",
      "Publishing: [Published] Processed event: System overload detected!. Severity: CRITICAL\n",
      "Output from node: publisher\n",
      "\n",
      "--- Subscriber Alpha Node ---\n",
      "ALPHA: Received and logged: '[Published] Processed event: System overload detected!. Severity: CRITICAL'\n",
      "Output from node: subscriber_alpha\n",
      "\n",
      "--- Subscriber Beta Node ---\n",
      "BETA: Analyzed message: '[Published] Processed event: System overload detected!. Severity: CRITICAL'. Action: Sent notification.\n",
      "Output from node: subscriber_beta\n",
      "\n",
      "--- Subscriber Critical Node ---\n",
      "CRITICAL_HANDLER: ALERT! Critical event processed: '[Published] Processed event: System overload detected!. Severity: CRITICAL'\n",
      "Output from node: subscriber_critical\n",
      "\n",
      "--- Summary Node ---\n",
      "  Event 90ea04b5-2005-4be7-a028-eb91f049e478 processing complete.\n",
      "      Published: [Published] Processed event: System overload detected!. Severity: CRITICAL\n",
      "      Alpha Logs: 1 entries\n",
      "      Beta Logs: 1 entries\n",
      "      Critical Logs: 1 entries\n",
      "Output from node: summary\n",
      "\n",
      "\n",
      "--- Final State (CRITICAL event) ---\n",
      "\n",
      "--- Publisher Node (Event ID: 90ea04b5-2005-4be7-a028-eb91f049e478) ---\n",
      "Publishing: [Published] Processed event: System overload detected!. Severity: CRITICAL\n",
      "\n",
      "--- Subscriber Alpha Node ---\n",
      "ALPHA: Received and logged: '[Published] Processed event: System overload detected!. Severity: CRITICAL'\n",
      "\n",
      "--- Subscriber Beta Node ---\n",
      "BETA: Analyzed message: '[Published] Processed event: System overload detected!. Severity: CRITICAL'. Action: Sent notification.\n",
      "\n",
      "--- Subscriber Critical Node ---\n",
      "CRITICAL_HANDLER: ALERT! Critical event processed: '[Published] Processed event: System overload detected!. Severity: CRITICAL'\n",
      "\n",
      "--- Summary Node ---\n",
      "  Event 90ea04b5-2005-4be7-a028-eb91f049e478 processing complete.\n",
      "      Published: [Published] Processed event: System overload detected!. Severity: CRITICAL\n",
      "      Alpha Logs: 1 entries\n",
      "      Beta Logs: 1 entries\n",
      "      Critical Logs: 1 entries\n",
      "initial_event_id: 90ea04b5-2005-4be7-a028-eb91f049e478\n",
      "initial_event_payload: {'data': 'System overload detected!', 'severity': 'CRITICAL'}\n",
      "published_message: [Published] Processed event: System overload detected!. Severity: CRITICAL\n",
      "subscriber_alpha_log: [\"ALPHA: Received and logged: '[Published] Processed event: System overload detected!. Severity: CRITICAL'\"]\n",
      "subscriber_beta_log: [\"BETA: Analyzed message: '[Published] Processed event: System overload detected!. Severity: CRITICAL'. Action: Sent notification.\"]\n",
      "subscriber_critical_log: [\"CRITICAL_HANDLER: ALERT! Critical event processed: '[Published] Processed event: System overload detected!. Severity: CRITICAL'\"]\n",
      "final_summary:   Event 90ea04b5-2005-4be7-a028-eb91f049e478 processing complete.\n",
      "      Published: [Published] Processed event: System overload detected!. Severity: CRITICAL\n",
      "      Alpha Logs: 1 entries\n",
      "      Beta Logs: 1 entries\n",
      "      Critical Logs: 1 entries\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n--- Running with a CRITICAL event ---\")\n",
    "critical_event_id = str(uuid.uuid4())\n",
    "critical_event_input = {\n",
    "    \"initial_event_id\": critical_event_id,\n",
    "    \"initial_event_payload\": {\"data\": \"System overload detected!\", \"severity\": \"CRITICAL\"}\n",
    "}\n",
    "final_state_critical = None\n",
    "for s in app.stream(critical_event_input):\n",
    "    print(f\"Output from node: {list(s.keys())[0]}\")\n",
    "    final_state_critical = s[list(s.keys())[0]]\n",
    "\n",
    "print(\"\\n\\n--- Final State (CRITICAL event) ---\")\n",
    "if final_state_critical:\n",
    "    final_state_critical_full = app.invoke(critical_event_input)\n",
    "    for key, value in final_state_critical_full.items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2785bbee-2d25-4adc-ba54-d61a2827d8f8",
   "metadata": {},
   "source": [
    "# v2 Multiple subscribers. Subscribers know anything about publisher."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b91f3e-3611-45a3-8e04-11a11a74813f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T18:40:24.625878Z",
     "iopub.status.busy": "2025-05-10T18:40:24.625034Z",
     "iopub.status.idle": "2025-05-10T18:40:24.639724Z",
     "shell.execute_reply": "2025-05-10T18:40:24.638400Z",
     "shell.execute_reply.started": "2025-05-10T18:40:24.625812Z"
    }
   },
   "source": [
    "My initial example was more of a sequential pipeline where data was passed along, not a true `Pub-Sub` model where subscribers react based on interest rather than direct wiring.\n",
    "\n",
    "To better model `Pub-Sub` with `LangGraph`, we need:\n",
    "\n",
    "- `Publisher`: A node that creates a message and \"publishes\" it with associated metadata (like topics or tags) into the shared state.\n",
    "- `Router/Dispatcher`: A mechanism (a node or conditional edge logic) that inspects the published message's metadata.\n",
    "- `Subscribers`: Nodes that have predefined \"interests\" (e.g., specific topics).\n",
    "- `Dynamic Invocation`: The router/dispatcher determines which subscribers are interested in the current message and ensures only they are invoked. Subscribers are not explicitly chained after the publisher in a fixed sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c897ced1-6f4d-45e0-97fa-8bab687abf63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T21:43:37.346194Z",
     "iopub.status.busy": "2025-05-09T21:43:37.345753Z",
     "iopub.status.idle": "2025-05-09T21:43:37.353017Z",
     "shell.execute_reply": "2025-05-09T21:43:37.352336Z",
     "shell.execute_reply.started": "2025-05-09T21:43:37.346158Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- 1. Define Subscriber Interests ---\n",
    "# Each subscriber declares what topics it's interested in.\n",
    "SUBSCRIBER_INTERESTS = {\n",
    "    \"subscriber_alpha\": [\"ALERT\", \"CRITICAL\"],  # Alpha is interested in ALERT or CRITICAL messages\n",
    "    \"subscriber_beta\": [\"UPDATE\", \"GENERAL\"],   # Beta is interested in UPDATE or GENERAL messages\n",
    "    \"subscriber_gamma\": [\"ALERT\", \"GENERAL\", \"STATS\"], # Gamma is interested in ALERT, GENERAL or STATS\n",
    "}\n",
    "\n",
    "# --- 2. Define the State ---\n",
    "class PubSubState(TypedDict):\n",
    "    # Input for a single \"publication\" cycle\n",
    "    event_id: str\n",
    "    event_payload: dict  # e.g., {\"data\": \"System overload\", \"type\": \"ALERT\", \"source\": \"sensor_123\"}\n",
    "    \n",
    "    # State generated by the publisher for the current event\n",
    "    published_message_content: Optional[str]\n",
    "    published_message_topics: List[str]  # Topics/tags determined by the publisher\n",
    "    \n",
    "    # Control flow: Who should run for the current event?\n",
    "    # List of subscriber node names that match the current event's topics\n",
    "    subscribers_matched_for_event: List[str] \n",
    "    # Set of subscriber node names that have completed processing for the current event\n",
    "    subscribers_completed_for_event: Set[str] \n",
    "    \n",
    "    # Aggregated logs from subscribers\n",
    "    # Using Annotated with operator.ior for dictionaries.\n",
    "    # Each key is a subscriber name, value is a list of its log messages for the current event.\n",
    "    subscriber_logs: Annotated[Dict[str, List[str]], operator.ior]\n",
    "    \n",
    "    # Could be used if processing a batch of events (not in this simple example)\n",
    "    # current_event_index: int \n",
    "    # all_events_processed: bool\n",
    "\n",
    "\n",
    "# --- Helper to initialize/reset logs for an event ---\n",
    "def get_initial_subscriber_logs_for_event() -> Dict[str, List[str]]:\n",
    "    return {sub_name: [] for sub_name in SUBSCRIBER_INTERESTS.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "589590cb-696d-4f1c-bf80-b62dbb716283",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T21:46:21.250355Z",
     "iopub.status.busy": "2025-05-09T21:46:21.249750Z",
     "iopub.status.idle": "2025-05-09T21:46:21.261744Z",
     "shell.execute_reply": "2025-05-09T21:46:21.261291Z",
     "shell.execute_reply.started": "2025-05-09T21:46:21.250303Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- 3. Define Node Functions ---\n",
    "\n",
    "def publisher_node(state: PubSubState) -> Dict:\n",
    "    \"\"\"\n",
    "    Processes an incoming event, \"publishes\" a message with derived topics,\n",
    "    and resets subscriber tracking for this new event.\n",
    "    \"\"\"\n",
    "    event_id = state[\"event_id\"]\n",
    "    payload = state[\"event_payload\"]\n",
    "    print(f\"\\n--- Publisher Node ---\")\n",
    "    print(f\"Processing Event ID: {event_id}, Payload: {payload}\")\n",
    "    \n",
    "    # Simulate deriving message content and topics from the payload\n",
    "    message_content = f\"Event: {payload.get('data', 'N/A')} (Source: {payload.get('source', 'Unknown')})\"\n",
    "    \n",
    "    # Determine topics for the message (example logic)\n",
    "    derived_topics = []\n",
    "    event_type = payload.get(\"type\", \"GENERAL\").upper()\n",
    "    if event_type:\n",
    "        derived_topics.append(event_type)\n",
    "    \n",
    "    if \"critical\" in payload.get(\"data\", \"\").lower() and \"CRITICAL\" not in derived_topics:\n",
    "        derived_topics.append(\"CRITICAL\")\n",
    "    if \"stats\" in payload.get(\"data\", \"\").lower() and \"STATS\" not in derived_topics:\n",
    "        derived_topics.append(\"STATS\")\n",
    "    if not derived_topics: # Ensure there's always at least one topic\n",
    "        derived_topics.append(\"GENERAL\")\n",
    "\n",
    "    print(f\"Published Message: '{message_content}' with Topics: {derived_topics}\")\n",
    "    \n",
    "    return {\n",
    "        \"published_message_content\": message_content,\n",
    "        \"published_message_topics\": derived_topics,\n",
    "        \"subscribers_matched_for_event\": [],  # Reset for this new event\n",
    "        \"subscribers_completed_for_event\": set(),  # Reset for this new event\n",
    "        \"subscriber_logs\": get_initial_subscriber_logs_for_event() # Reset logs for the new event\n",
    "    }\n",
    "\n",
    "def router_node(state: PubSubState) -> Dict:\n",
    "    \"\"\"\n",
    "    Inspects the published message's topics and determines which subscribers\n",
    "    are interested (i.e., subscribed to at least one of those topics).\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Router Node ---\")\n",
    "    published_topics = state[\"published_message_topics\"]\n",
    "    matched_subscribers = []\n",
    "    \n",
    "    for sub_name, interests in SUBSCRIBER_INTERESTS.items():\n",
    "        # Check if any of the subscriber's interests (topics they care about)\n",
    "        # are present in the message's topics\n",
    "        if any(topic in published_topics for topic in interests):\n",
    "            matched_subscribers.append(sub_name)\n",
    "            \n",
    "    print(f\"Message Topics: {published_topics}\")\n",
    "    print(f\"Subscribers Matched for these topics: {matched_subscribers}\")\n",
    "    \n",
    "    return {\"subscribers_matched_for_event\": matched_subscribers}\n",
    "\n",
    "\n",
    "# --- Generic Subscriber Node Factory ---\n",
    "# This creates a unique node function for each named subscriber.\n",
    "def create_subscriber_node(subscriber_name: str):\n",
    "    def subscriber_node_logic(state: PubSubState) -> Dict:\n",
    "        # This node should only really execute if it's its turn.\n",
    "        # The conditional routing should handle this, but defensive checks are fine.\n",
    "        print(f\"\\n--- {subscriber_name.upper()} Node ---\")\n",
    "\n",
    "        message = state[\"published_message_content\"]\n",
    "        topics = state[\"published_message_topics\"]\n",
    "        \n",
    "        # Simulate subscriber processing the message\n",
    "        log_entry = (f\"{subscriber_name.upper()}: Processed message '{message}' \"\n",
    "                     f\"(Relevant Topics for this message: {topics})\")\n",
    "        print(log_entry)\n",
    "        \n",
    "        # Update logs:\n",
    "        # Read current logs for this specific subscriber, append new entry.\n",
    "        # The state's `subscriber_logs` is Annotated with operator.ior,\n",
    "        # so we return a dict that will be merged.\n",
    "        new_log_for_this_subscriber = {\n",
    "            subscriber_name: state[\"subscriber_logs\"].get(subscriber_name, []) + [log_entry]\n",
    "        }\n",
    "        \n",
    "        # Mark this subscriber as having completed for the current event\n",
    "        updated_completed_set = set(state[\"subscribers_completed_for_event\"]) # Create a mutable copy\n",
    "        updated_completed_set.add(subscriber_name)\n",
    "        \n",
    "        return {\n",
    "            \"subscriber_logs\": new_log_for_this_subscriber, # This dict will be merged into the state\n",
    "            \"subscribers_completed_for_event\": updated_completed_set\n",
    "        }\n",
    "    return subscriber_node_logic\n",
    "\n",
    "# Create actual subscriber node functions\n",
    "subscriber_alpha_node = create_subscriber_node(\"subscriber_alpha\")\n",
    "subscriber_beta_node = create_subscriber_node(\"subscriber_beta\")\n",
    "subscriber_gamma_node = create_subscriber_node(\"subscriber_gamma\")\n",
    "\n",
    "\n",
    "def final_summary_node(state: PubSubState) -> Dict:\n",
    "    \"\"\"\n",
    "    Prints a summary of the processing for the current event.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Event Processing Summary ---\")\n",
    "    print(f\"Event ID: {state['event_id']}\")\n",
    "    print(f\"Published Message: {state['published_message_content']}\")\n",
    "    print(f\"Message Topics: {state['published_message_topics']}\")\n",
    "    print(f\"Matched Subscribers: {state['subscribers_matched_for_event']}\")\n",
    "    print(f\"Completed Subscribers: {state['subscribers_completed_for_event']}\")\n",
    "    print(\"Subscriber Logs for this event:\")\n",
    "    \n",
    "    # Sort by subscriber name for consistent output\n",
    "    sorted_log_keys = sorted(state[\"subscriber_logs\"].keys())\n",
    "\n",
    "    for sub_name in sorted_log_keys:\n",
    "        logs = state[\"subscriber_logs\"][sub_name]\n",
    "        if logs:  # Only print if the subscriber actually logged something for this event\n",
    "            print(f\"  Logs from {sub_name.upper()}:\")\n",
    "            for log_entry in logs:\n",
    "                # Extract just the processing part of the log for brevity\n",
    "                processed_part = log_entry.split(': ', 1)[1] if ': ' in log_entry else log_entry\n",
    "                print(f\"    - {processed_part}\")\n",
    "        # else:\n",
    "            # print(f\"  No logs from {sub_name.upper()} for this event.\") # Optional: for debugging\n",
    "    print(\"---------------------------------\")\n",
    "    return {} # No state change, just a terminal action for this event's processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49eb3f93-e399-4a1e-922e-a62e34f30580",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T21:46:35.162585Z",
     "iopub.status.busy": "2025-05-09T21:46:35.162234Z",
     "iopub.status.idle": "2025-05-09T21:46:35.169869Z",
     "shell.execute_reply": "2025-05-09T21:46:35.168793Z",
     "shell.execute_reply.started": "2025-05-09T21:46:35.162558Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- 4. Conditional Logic for Dispatching Subscribers ---\n",
    "def route_to_next_subscriber_or_summary(state: PubSubState) -> str:\n",
    "    \"\"\"\n",
    "    This function is the core of the Pub-Sub dispatch logic.\n",
    "    It decides which node to go to next after the router_node has identified\n",
    "    matched subscribers, or after a subscriber has finished.\n",
    "\n",
    "    Returns:\n",
    "        The name of the next node to execute.\n",
    "    \"\"\"\n",
    "    matched_subscribers = state[\"subscribers_matched_for_event\"]\n",
    "    completed_subscribers = state[\"subscribers_completed_for_event\"]\n",
    "    \n",
    "    if not matched_subscribers:\n",
    "        # No subscribers were interested in this event's topics.\n",
    "        print(\"Conditional Dispatch: No subscribers matched this event. Routing to summary.\")\n",
    "        return \"summary\"\n",
    "\n",
    "    # Find the next matched subscriber that hasn't completed yet\n",
    "    for sub_name in matched_subscribers:\n",
    "        if sub_name not in completed_subscribers:\n",
    "            print(f\"Conditional Dispatch: Routing to next pending subscriber: {sub_name}\")\n",
    "            return sub_name  # Return the node name of the subscriber to run\n",
    "            \n",
    "    # If we reach here, all matched subscribers for the current event have completed.\n",
    "    print(\"Conditional Dispatch: All matched subscribers have processed the event. Routing to summary.\")\n",
    "    return \"summary\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5a6a35f-f43a-453d-b60b-a1bd5d98d9b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T22:01:35.537150Z",
     "iopub.status.busy": "2025-05-09T22:01:35.536678Z",
     "iopub.status.idle": "2025-05-09T22:01:35.550108Z",
     "shell.execute_reply": "2025-05-09T22:01:35.549725Z",
     "shell.execute_reply.started": "2025-05-09T22:01:35.537112Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- 5. Define the Graph Workflow ---\n",
    "workflow = StateGraph(PubSubState)\n",
    "\n",
    "# Add nodes to the graph\n",
    "workflow.add_node(\"publisher\", publisher_node)\n",
    "workflow.add_node(\"router\", router_node)\n",
    "\n",
    "# Add each defined subscriber node to the graph\n",
    "workflow.add_node(\"subscriber_alpha\", subscriber_alpha_node)\n",
    "workflow.add_node(\"subscriber_beta\", subscriber_beta_node)\n",
    "workflow.add_node(\"subscriber_gamma\", subscriber_gamma_node)\n",
    "\n",
    "workflow.add_node(\"summary\", final_summary_node)\n",
    "\n",
    "\n",
    "# --- Define Edges and Control Flow ---\n",
    "\n",
    "# Start with the publisher\n",
    "workflow.set_entry_point(\"publisher\")\n",
    "\n",
    "# After publishing, route to determine interested subscribers\n",
    "workflow.add_edge(\"publisher\", \"router\")\n",
    "\n",
    "# This is the main dispatch hub:\n",
    "# After the router identifies potential subscribers, or after a subscriber finishes,\n",
    "# this conditional edge decides what to do next.\n",
    "workflow.add_conditional_edges(\n",
    "    \"router\",  # The decision is made *after* the router_node runs.\n",
    "    route_to_next_subscriber_or_summary,  # The function that returns the name of the next node.\n",
    "    {\n",
    "        # Map returned names to actual graph nodes\n",
    "        \"subscriber_alpha\": \"subscriber_alpha\",\n",
    "        \"subscriber_beta\": \"subscriber_beta\",\n",
    "        \"subscriber_gamma\": \"subscriber_gamma\",\n",
    "        \"summary\": \"summary\"  # If no more subscribers for this event, or none matched\n",
    "    }\n",
    ")\n",
    "\n",
    "# After each subscriber finishes, it needs to go back to the decision point\n",
    "# to allow the next pending subscriber (for the same event) to run, or to go to summary.\n",
    "# The 'router' node here serves as that decision point trigger because the conditional\n",
    "# edge is attached to it. When a subscriber transitions to 'router', the router logic\n",
    "# runs (it will find the same matched_subscribers for the current event), and then\n",
    "# `route_to_next_subscriber_or_summary` is called again, which will now see the updated\n",
    "# `subscribers_completed_for_event` and pick the next one or go to summary.\n",
    "workflow.add_edge(\"subscriber_alpha\", \"router\")\n",
    "workflow.add_edge(\"subscriber_beta\", \"router\")\n",
    "workflow.add_edge(\"subscriber_gamma\", \"router\")\n",
    "\n",
    "# Once the summary node is reached for an event, the graph ends for that event.\n",
    "workflow.add_edge(\"summary\", END)\n",
    "\n",
    "\n",
    "# --- 6. Compile the Graph ---\n",
    "# mem_saver = MemorySaver() # Optional: for inspecting state at each step if needed\n",
    "app = workflow.compile() # checkpoint_saver=mem_saver if using checkpoints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8d2b0c4-bcf2-450a-99a5-ff9f2ed6a235",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-09T22:01:39.028244Z",
     "iopub.status.busy": "2025-05-09T22:01:39.028077Z",
     "iopub.status.idle": "2025-05-09T22:01:59.877035Z",
     "shell.execute_reply": "2025-05-09T22:01:59.876187Z",
     "shell.execute_reply.started": "2025-05-09T22:01:39.028231Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to reach https://mermaid.ink/ API while trying to render your graph after 1 retries. To resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 461\u001b[0m     httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1303\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1300\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1301\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1302\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1159\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTimeoutError\u001b[0m: The read operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:798\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    796\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--> 798\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    801\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/util/retry.py:550\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 550\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/packages/six.py:770\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 770\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:468\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 468\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:357\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[1;32m    358\u001b[0m         \u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m timeout_value\n\u001b[1;32m    359\u001b[0m     )\n\u001b[1;32m    361\u001b[0m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3. In Python 2 we have\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;66;03m# to specifically catch it and throw the timeout error\u001b[39;00m\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/runnables/graph_mermaid.py:430\u001b[0m, in \u001b[0;36m_render_mermaid_using_api\u001b[0;34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 430\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m requests\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mok:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/adapters.py:713\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[0;32m--> 713\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n",
      "\u001b[0;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image, display\n\u001b[0;32m----> 3\u001b[0m display(Image(\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/runnables/graph.py:685\u001b[0m, in \u001b[0;36mGraph.draw_mermaid_png\u001b[0;34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_mermaid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m draw_mermaid_png\n\u001b[1;32m    679\u001b[0m mermaid_syntax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_mermaid(\n\u001b[1;32m    680\u001b[0m     curve_style\u001b[38;5;241m=\u001b[39mcurve_style,\n\u001b[1;32m    681\u001b[0m     node_colors\u001b[38;5;241m=\u001b[39mnode_colors,\n\u001b[1;32m    682\u001b[0m     wrap_label_n_words\u001b[38;5;241m=\u001b[39mwrap_label_n_words,\n\u001b[1;32m    683\u001b[0m     frontmatter_config\u001b[38;5;241m=\u001b[39mfrontmatter_config,\n\u001b[1;32m    684\u001b[0m )\n\u001b[0;32m--> 685\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/runnables/graph_mermaid.py:293\u001b[0m, in \u001b[0;36mdraw_mermaid_png\u001b[0;34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay)\u001b[0m\n\u001b[1;32m    287\u001b[0m     img_bytes \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m    288\u001b[0m         _render_mermaid_using_pyppeteer(\n\u001b[1;32m    289\u001b[0m             mermaid_syntax, output_file_path, background_color, padding\n\u001b[1;32m    290\u001b[0m         )\n\u001b[1;32m    291\u001b[0m     )\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m draw_method \u001b[38;5;241m==\u001b[39m MermaidDrawMethod\u001b[38;5;241m.\u001b[39mAPI:\n\u001b[0;32m--> 293\u001b[0m     img_bytes \u001b[38;5;241m=\u001b[39m \u001b[43m_render_mermaid_using_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     supported_methods \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([m\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MermaidDrawMethod])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/runnables/graph_mermaid.py:462\u001b[0m, in \u001b[0;36m_render_mermaid_using_api\u001b[0;34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    459\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reach https://mermaid.ink/ API while trying to render \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    460\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour graph after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m retries. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    461\u001b[0m             ) \u001b[38;5;241m+\u001b[39m error_msg_suffix\n\u001b[0;32m--> 462\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;66;03m# This should not be reached, but just in case\u001b[39;00m\n\u001b[1;32m    465\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reach https://mermaid.ink/ API while trying to render \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour graph after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m retries. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    468\u001b[0m ) \u001b[38;5;241m+\u001b[39m error_msg_suffix\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to reach https://mermaid.ink/ API while trying to render your graph after 1 retries. To resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46c323ab-c5ad-4a17-9a88-b0c10102fd81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T21:47:19.943717Z",
     "iopub.status.busy": "2025-05-09T21:47:19.942212Z",
     "iopub.status.idle": "2025-05-09T21:47:19.950324Z",
     "shell.execute_reply": "2025-05-09T21:47:19.949570Z",
     "shell.execute_reply.started": "2025-05-09T21:47:19.943595Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- 7. Run the Graph with Different Example Events ---\n",
    "\n",
    "def run_event_through_pubsub(event_payload: dict):\n",
    "    event_id = str(uuid.uuid4())\n",
    "    print(f\"\\n\\n<<<<< STARTING NEW EVENT: ID {event_id}, Type: {event_payload.get('type', 'N/A')} >>>>>\")\n",
    "    \n",
    "    initial_state = {\n",
    "        \"event_id\": event_id,\n",
    "        \"event_payload\": event_payload,\n",
    "        # Other fields will be initialized by the publisher or are optional initially\n",
    "    }\n",
    "    \n",
    "    # Stream the execution to see node outputs\n",
    "    for step_output in app.stream(initial_state):\n",
    "        node_name = list(step_output.keys())[0]\n",
    "        print(f\"Output from node: {node_name} (Value keys: {list(step_output[node_name].keys()) if step_output[node_name] else 'None'})\")\n",
    "        # For very verbose output of state after each node:\n",
    "        # print(f\"Full state after {node_name}: {step_output[node_name]}\")\n",
    "    \n",
    "    print(f\"<<<<< FINISHED EVENT: ID {event_id} >>>>>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cccdbdb-fd39-4b5a-9589-3a6827c60f6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T21:47:34.626225Z",
     "iopub.status.busy": "2025-05-09T21:47:34.625797Z",
     "iopub.status.idle": "2025-05-09T21:47:34.633452Z",
     "shell.execute_reply": "2025-05-09T21:47:34.632999Z",
     "shell.execute_reply.started": "2025-05-09T21:47:34.626190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<<<<< STARTING NEW EVENT: ID d544f6a9-932b-47df-8bda-d844b4c2877f, Type: ALERT >>>>>\n",
      "\n",
      "--- Publisher Node ---\n",
      "Processing Event ID: d544f6a9-932b-47df-8bda-d844b4c2877f, Payload: {'data': 'System critical failure imminent!', 'type': 'ALERT', 'source': 'CPU_Monitor'}\n",
      "Published Message: 'Event: System critical failure imminent! (Source: CPU_Monitor)' with Topics: ['ALERT', 'CRITICAL']\n",
      "Output from node: publisher (Value keys: ['published_message_content', 'published_message_topics', 'subscribers_matched_for_event', 'subscribers_completed_for_event', 'subscriber_logs'])\n",
      "\n",
      "--- Router Node ---\n",
      "Message Topics: ['ALERT', 'CRITICAL']\n",
      "Subscribers Matched for these topics: ['subscriber_alpha', 'subscriber_gamma']\n",
      "Conditional Dispatch: Routing to next pending subscriber: subscriber_alpha\n",
      "Output from node: router (Value keys: ['subscribers_matched_for_event'])\n",
      "\n",
      "--- SUBSCRIBER_ALPHA Node ---\n",
      "SUBSCRIBER_ALPHA: Processed message 'Event: System critical failure imminent! (Source: CPU_Monitor)' (Relevant Topics for this message: ['ALERT', 'CRITICAL'])\n",
      "Output from node: subscriber_alpha (Value keys: ['subscriber_logs', 'subscribers_completed_for_event'])\n",
      "\n",
      "--- Router Node ---\n",
      "Message Topics: ['ALERT', 'CRITICAL']\n",
      "Subscribers Matched for these topics: ['subscriber_alpha', 'subscriber_gamma']\n",
      "Conditional Dispatch: Routing to next pending subscriber: subscriber_gamma\n",
      "Output from node: router (Value keys: ['subscribers_matched_for_event'])\n",
      "\n",
      "--- SUBSCRIBER_GAMMA Node ---\n",
      "SUBSCRIBER_GAMMA: Processed message 'Event: System critical failure imminent! (Source: CPU_Monitor)' (Relevant Topics for this message: ['ALERT', 'CRITICAL'])\n",
      "Output from node: subscriber_gamma (Value keys: ['subscriber_logs', 'subscribers_completed_for_event'])\n",
      "\n",
      "--- Router Node ---\n",
      "Message Topics: ['ALERT', 'CRITICAL']\n",
      "Subscribers Matched for these topics: ['subscriber_alpha', 'subscriber_gamma']\n",
      "Conditional Dispatch: All matched subscribers have processed the event. Routing to summary.\n",
      "Output from node: router (Value keys: ['subscribers_matched_for_event'])\n",
      "\n",
      "--- Event Processing Summary ---\n",
      "Event ID: d544f6a9-932b-47df-8bda-d844b4c2877f\n",
      "Published Message: Event: System critical failure imminent! (Source: CPU_Monitor)\n",
      "Message Topics: ['ALERT', 'CRITICAL']\n",
      "Matched Subscribers: ['subscriber_alpha', 'subscriber_gamma']\n",
      "Completed Subscribers: {'subscriber_alpha', 'subscriber_gamma'}\n",
      "Subscriber Logs for this event:\n",
      "  Logs from SUBSCRIBER_ALPHA:\n",
      "    - Processed message 'Event: System critical failure imminent! (Source: CPU_Monitor)' (Relevant Topics for this message: ['ALERT', 'CRITICAL'])\n",
      "  Logs from SUBSCRIBER_GAMMA:\n",
      "    - Processed message 'Event: System critical failure imminent! (Source: CPU_Monitor)' (Relevant Topics for this message: ['ALERT', 'CRITICAL'])\n",
      "---------------------------------\n",
      "Output from node: summary (Value keys: None)\n",
      "<<<<< FINISHED EVENT: ID d544f6a9-932b-47df-8bda-d844b4c2877f >>>>>\n"
     ]
    }
   ],
   "source": [
    "# Example Event 1: An ALERT that should trigger Alpha and Gamma\n",
    "event1_payload = {\"data\": \"System critical failure imminent!\", \"type\": \"ALERT\", \"source\": \"CPU_Monitor\"}\n",
    "run_event_through_pubsub(event1_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85b23a3d-ec17-4806-81fd-76a1aa120e72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T21:47:45.788333Z",
     "iopub.status.busy": "2025-05-09T21:47:45.787872Z",
     "iopub.status.idle": "2025-05-09T21:47:45.797247Z",
     "shell.execute_reply": "2025-05-09T21:47:45.796801Z",
     "shell.execute_reply.started": "2025-05-09T21:47:45.788291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<<<<< STARTING NEW EVENT: ID aa48ed2e-ea71-4b35-b58a-83200ecf3e8b, Type: UPDATE >>>>>\n",
      "\n",
      "--- Publisher Node ---\n",
      "Processing Event ID: aa48ed2e-ea71-4b35-b58a-83200ecf3e8b, Payload: {'data': \"User profile for 'jane_doe' updated.\", 'type': 'UPDATE', 'source': 'AuthService'}\n",
      "Published Message: 'Event: User profile for 'jane_doe' updated. (Source: AuthService)' with Topics: ['UPDATE']\n",
      "Output from node: publisher (Value keys: ['published_message_content', 'published_message_topics', 'subscribers_matched_for_event', 'subscribers_completed_for_event', 'subscriber_logs'])\n",
      "\n",
      "--- Router Node ---\n",
      "Message Topics: ['UPDATE']\n",
      "Subscribers Matched for these topics: ['subscriber_beta']\n",
      "Conditional Dispatch: Routing to next pending subscriber: subscriber_beta\n",
      "Output from node: router (Value keys: ['subscribers_matched_for_event'])\n",
      "\n",
      "--- SUBSCRIBER_BETA Node ---\n",
      "SUBSCRIBER_BETA: Processed message 'Event: User profile for 'jane_doe' updated. (Source: AuthService)' (Relevant Topics for this message: ['UPDATE'])\n",
      "Output from node: subscriber_beta (Value keys: ['subscriber_logs', 'subscribers_completed_for_event'])\n",
      "\n",
      "--- Router Node ---\n",
      "Message Topics: ['UPDATE']\n",
      "Subscribers Matched for these topics: ['subscriber_beta']\n",
      "Conditional Dispatch: All matched subscribers have processed the event. Routing to summary.\n",
      "Output from node: router (Value keys: ['subscribers_matched_for_event'])\n",
      "\n",
      "--- Event Processing Summary ---\n",
      "Event ID: aa48ed2e-ea71-4b35-b58a-83200ecf3e8b\n",
      "Published Message: Event: User profile for 'jane_doe' updated. (Source: AuthService)\n",
      "Message Topics: ['UPDATE']\n",
      "Matched Subscribers: ['subscriber_beta']\n",
      "Completed Subscribers: {'subscriber_beta'}\n",
      "Subscriber Logs for this event:\n",
      "  Logs from SUBSCRIBER_BETA:\n",
      "    - Processed message 'Event: User profile for 'jane_doe' updated. (Source: AuthService)' (Relevant Topics for this message: ['UPDATE'])\n",
      "---------------------------------\n",
      "Output from node: summary (Value keys: None)\n",
      "<<<<< FINISHED EVENT: ID aa48ed2e-ea71-4b35-b58a-83200ecf3e8b >>>>>\n"
     ]
    }
   ],
   "source": [
    "# Example Event 2: An UPDATE that should trigger Beta\n",
    "event2_payload = {\"data\": \"User profile for 'jane_doe' updated.\", \"type\": \"UPDATE\", \"source\": \"AuthService\"}\n",
    "run_event_through_pubsub(event2_payload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4601bfc6-0386-4a84-8f5a-7f7eb984e732",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T21:47:59.978875Z",
     "iopub.status.busy": "2025-05-09T21:47:59.978336Z",
     "iopub.status.idle": "2025-05-09T21:47:59.989506Z",
     "shell.execute_reply": "2025-05-09T21:47:59.989087Z",
     "shell.execute_reply.started": "2025-05-09T21:47:59.978827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<<<<< STARTING NEW EVENT: ID 1732b3a5-af92-45cb-8918-cd51dd95b124, Type: GENERAL >>>>>\n",
      "\n",
      "--- Publisher Node ---\n",
      "Processing Event ID: 1732b3a5-af92-45cb-8918-cd51dd95b124, Payload: {'data': 'Hourly user activity stats generated.', 'type': 'GENERAL', 'source': 'AnalyticsEngine'}\n",
      "Published Message: 'Event: Hourly user activity stats generated. (Source: AnalyticsEngine)' with Topics: ['GENERAL', 'STATS']\n",
      "Output from node: publisher (Value keys: ['published_message_content', 'published_message_topics', 'subscribers_matched_for_event', 'subscribers_completed_for_event', 'subscriber_logs'])\n",
      "\n",
      "--- Router Node ---\n",
      "Message Topics: ['GENERAL', 'STATS']\n",
      "Subscribers Matched for these topics: ['subscriber_beta', 'subscriber_gamma']\n",
      "Conditional Dispatch: Routing to next pending subscriber: subscriber_beta\n",
      "Output from node: router (Value keys: ['subscribers_matched_for_event'])\n",
      "\n",
      "--- SUBSCRIBER_BETA Node ---\n",
      "SUBSCRIBER_BETA: Processed message 'Event: Hourly user activity stats generated. (Source: AnalyticsEngine)' (Relevant Topics for this message: ['GENERAL', 'STATS'])\n",
      "Output from node: subscriber_beta (Value keys: ['subscriber_logs', 'subscribers_completed_for_event'])\n",
      "\n",
      "--- Router Node ---\n",
      "Message Topics: ['GENERAL', 'STATS']\n",
      "Subscribers Matched for these topics: ['subscriber_beta', 'subscriber_gamma']\n",
      "Conditional Dispatch: Routing to next pending subscriber: subscriber_gamma\n",
      "Output from node: router (Value keys: ['subscribers_matched_for_event'])\n",
      "\n",
      "--- SUBSCRIBER_GAMMA Node ---\n",
      "SUBSCRIBER_GAMMA: Processed message 'Event: Hourly user activity stats generated. (Source: AnalyticsEngine)' (Relevant Topics for this message: ['GENERAL', 'STATS'])\n",
      "Output from node: subscriber_gamma (Value keys: ['subscriber_logs', 'subscribers_completed_for_event'])\n",
      "\n",
      "--- Router Node ---\n",
      "Message Topics: ['GENERAL', 'STATS']\n",
      "Subscribers Matched for these topics: ['subscriber_beta', 'subscriber_gamma']\n",
      "Conditional Dispatch: All matched subscribers have processed the event. Routing to summary.\n",
      "Output from node: router (Value keys: ['subscribers_matched_for_event'])\n",
      "\n",
      "--- Event Processing Summary ---\n",
      "Event ID: 1732b3a5-af92-45cb-8918-cd51dd95b124\n",
      "Published Message: Event: Hourly user activity stats generated. (Source: AnalyticsEngine)\n",
      "Message Topics: ['GENERAL', 'STATS']\n",
      "Matched Subscribers: ['subscriber_beta', 'subscriber_gamma']\n",
      "Completed Subscribers: {'subscriber_gamma', 'subscriber_beta'}\n",
      "Subscriber Logs for this event:\n",
      "  Logs from SUBSCRIBER_BETA:\n",
      "    - Processed message 'Event: Hourly user activity stats generated. (Source: AnalyticsEngine)' (Relevant Topics for this message: ['GENERAL', 'STATS'])\n",
      "  Logs from SUBSCRIBER_GAMMA:\n",
      "    - Processed message 'Event: Hourly user activity stats generated. (Source: AnalyticsEngine)' (Relevant Topics for this message: ['GENERAL', 'STATS'])\n",
      "---------------------------------\n",
      "Output from node: summary (Value keys: None)\n",
      "<<<<< FINISHED EVENT: ID 1732b3a5-af92-45cb-8918-cd51dd95b124 >>>>>\n"
     ]
    }
   ],
   "source": [
    "# Example Event 3: A GENERAL STATS event that should trigger Beta and Gamma\n",
    "event3_payload = {\"data\": \"Hourly user activity stats generated.\", \"type\": \"GENERAL\", \"source\": \"AnalyticsEngine\"}\n",
    "run_event_through_pubsub(event3_payload) # Note: \"STATS\" might also be derived by publisher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff4d686e-2972-4db3-8a77-b9936e11f148",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T21:48:11.364656Z",
     "iopub.status.busy": "2025-05-09T21:48:11.364251Z",
     "iopub.status.idle": "2025-05-09T21:48:11.372698Z",
     "shell.execute_reply": "2025-05-09T21:48:11.372083Z",
     "shell.execute_reply.started": "2025-05-09T21:48:11.364613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<<<<< STARTING NEW EVENT: ID 465c885c-a3a6-4195-b6f1-3f581fdd78e7, Type: LOG >>>>>\n",
      "\n",
      "--- Publisher Node ---\n",
      "Processing Event ID: 465c885c-a3a6-4195-b6f1-3f581fdd78e7, Payload: {'data': 'Routine maintenance log.', 'type': 'LOG', 'source': 'SystemDaemon'}\n",
      "Published Message: 'Event: Routine maintenance log. (Source: SystemDaemon)' with Topics: ['LOG']\n",
      "Output from node: publisher (Value keys: ['published_message_content', 'published_message_topics', 'subscribers_matched_for_event', 'subscribers_completed_for_event', 'subscriber_logs'])\n",
      "\n",
      "--- Router Node ---\n",
      "Message Topics: ['LOG']\n",
      "Subscribers Matched for these topics: []\n",
      "Conditional Dispatch: No subscribers matched this event. Routing to summary.\n",
      "Output from node: router (Value keys: ['subscribers_matched_for_event'])\n",
      "\n",
      "--- Event Processing Summary ---\n",
      "Event ID: 465c885c-a3a6-4195-b6f1-3f581fdd78e7\n",
      "Published Message: Event: Routine maintenance log. (Source: SystemDaemon)\n",
      "Message Topics: ['LOG']\n",
      "Matched Subscribers: []\n",
      "Completed Subscribers: set()\n",
      "Subscriber Logs for this event:\n",
      "---------------------------------\n",
      "Output from node: summary (Value keys: None)\n",
      "<<<<< FINISHED EVENT: ID 465c885c-a3a6-4195-b6f1-3f581fdd78e7 >>>>>\n"
     ]
    }
   ],
   "source": [
    "# Example Event 4: An event with a type no one is directly subscribed to (becomes GENERAL)\n",
    "event4_payload = {\"data\": \"Routine maintenance log.\", \"type\": \"LOG\", \"source\": \"SystemDaemon\"}\n",
    "run_event_through_pubsub(event4_payload) # Publisher might default this to \"GENERAL\" if \"LOG\" is not a primary topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c62cb2d0-4ff7-470a-a468-437f6e6d3de9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T21:48:25.028627Z",
     "iopub.status.busy": "2025-05-09T21:48:25.027195Z",
     "iopub.status.idle": "2025-05-09T21:48:25.034501Z",
     "shell.execute_reply": "2025-05-09T21:48:25.033764Z",
     "shell.execute_reply.started": "2025-05-09T21:48:25.028573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<<<<< STARTING NEW EVENT: ID 6a33678c-0e3c-44a5-973f-b1f1cf832f6c, Type: ALERT >>>>>\n",
      "\n",
      "--- Publisher Node ---\n",
      "Processing Event ID: 6a33678c-0e3c-44a5-973f-b1f1cf832f6c, Payload: {'data': 'Critical spike in error stats detected!', 'type': 'ALERT', 'source': 'Aggregator'}\n",
      "Published Message: 'Event: Critical spike in error stats detected! (Source: Aggregator)' with Topics: ['ALERT', 'CRITICAL', 'STATS']\n",
      "Output from node: publisher (Value keys: ['published_message_content', 'published_message_topics', 'subscribers_matched_for_event', 'subscribers_completed_for_event', 'subscriber_logs'])\n",
      "\n",
      "--- Router Node ---\n",
      "Message Topics: ['ALERT', 'CRITICAL', 'STATS']\n",
      "Subscribers Matched for these topics: ['subscriber_alpha', 'subscriber_gamma']\n",
      "Conditional Dispatch: Routing to next pending subscriber: subscriber_alpha\n",
      "Output from node: router (Value keys: ['subscribers_matched_for_event'])\n",
      "\n",
      "--- SUBSCRIBER_ALPHA Node ---\n",
      "SUBSCRIBER_ALPHA: Processed message 'Event: Critical spike in error stats detected! (Source: Aggregator)' (Relevant Topics for this message: ['ALERT', 'CRITICAL', 'STATS'])\n",
      "Output from node: subscriber_alpha (Value keys: ['subscriber_logs', 'subscribers_completed_for_event'])\n",
      "\n",
      "--- Router Node ---\n",
      "Message Topics: ['ALERT', 'CRITICAL', 'STATS']\n",
      "Subscribers Matched for these topics: ['subscriber_alpha', 'subscriber_gamma']\n",
      "Conditional Dispatch: Routing to next pending subscriber: subscriber_gamma\n",
      "Output from node: router (Value keys: ['subscribers_matched_for_event'])\n",
      "\n",
      "--- SUBSCRIBER_GAMMA Node ---\n",
      "SUBSCRIBER_GAMMA: Processed message 'Event: Critical spike in error stats detected! (Source: Aggregator)' (Relevant Topics for this message: ['ALERT', 'CRITICAL', 'STATS'])\n",
      "Output from node: subscriber_gamma (Value keys: ['subscriber_logs', 'subscribers_completed_for_event'])\n",
      "\n",
      "--- Router Node ---\n",
      "Message Topics: ['ALERT', 'CRITICAL', 'STATS']\n",
      "Subscribers Matched for these topics: ['subscriber_alpha', 'subscriber_gamma']\n",
      "Conditional Dispatch: All matched subscribers have processed the event. Routing to summary.\n",
      "Output from node: router (Value keys: ['subscribers_matched_for_event'])\n",
      "\n",
      "--- Event Processing Summary ---\n",
      "Event ID: 6a33678c-0e3c-44a5-973f-b1f1cf832f6c\n",
      "Published Message: Event: Critical spike in error stats detected! (Source: Aggregator)\n",
      "Message Topics: ['ALERT', 'CRITICAL', 'STATS']\n",
      "Matched Subscribers: ['subscriber_alpha', 'subscriber_gamma']\n",
      "Completed Subscribers: {'subscriber_alpha', 'subscriber_gamma'}\n",
      "Subscriber Logs for this event:\n",
      "  Logs from SUBSCRIBER_ALPHA:\n",
      "    - Processed message 'Event: Critical spike in error stats detected! (Source: Aggregator)' (Relevant Topics for this message: ['ALERT', 'CRITICAL', 'STATS'])\n",
      "  Logs from SUBSCRIBER_GAMMA:\n",
      "    - Processed message 'Event: Critical spike in error stats detected! (Source: Aggregator)' (Relevant Topics for this message: ['ALERT', 'CRITICAL', 'STATS'])\n",
      "---------------------------------\n",
      "Output from node: summary (Value keys: None)\n",
      "<<<<< FINISHED EVENT: ID 6a33678c-0e3c-44a5-973f-b1f1cf832f6c >>>>>\n"
     ]
    }
   ],
   "source": [
    "# Example Event 5: An event with CRITICAL and STATS implications\n",
    "event5_payload = {\"data\": \"Critical spike in error stats detected!\", \"type\": \"ALERT\", \"source\": \"Aggregator\"}\n",
    "run_event_through_pubsub(event5_payload) # Alpha (ALERT, CRITICAL) and Gamma (ALERT, STATS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194abc7b-151e-450e-adc5-f7b89cd7d98b",
   "metadata": {},
   "source": [
    "# v3 + Multiple Publishers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdd064e-f54e-4a7f-a271-205efc3aecac",
   "metadata": {},
   "source": [
    "The Subscriber logic is the same.\n",
    "\n",
    "Okay, let's refactor the code to include multiple distinct publisher nodes. The core idea is:\n",
    "\n",
    "1.  **Identify Event Source:** The incoming event will need some way to indicate its origin or type (e.g., \"sensor_event\", \"user_action_event\", \"system_event\").\n",
    "2.  **Publisher Router Node:** An initial node in the graph will look at this event source and route it to the appropriate specialized publisher node.\n",
    "3.  **Specialized Publisher Nodes:** We'll create a few different publisher functions, each tailored to a type of event. For example:\n",
    "    *   `publisher_sensor_events_node`: Handles events from IoT sensors.\n",
    "    *   `publisher_user_actions_node`: Handles events triggered by user interactions.\n",
    "    *   `publisher_system_alerts_node`: Handles internal system alerts.\n",
    "4.  **Common Subscriber Router:** After a specialized publisher node processes the event and \"publishes\" its message (i.e., sets `published_message_content` and `published_message_topics` in the state), the flow goes to the *same* `subscriber_router_node` we had before. This node doesn't care *which* publisher created the message, only what its topics are.\n",
    "5.  **Subscriber Logic:** The subscriber matching and execution logic remains the same.\n",
    "\n",
    "\n",
    "This structure now clearly separates different publishing concerns while maintaining a common pipeline for subscriber matching and execution, which is much closer to how multiple publishers would interact with a Pub-Sub system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf0d1e0e-a8a4-4df8-839d-bffddce11bf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T22:50:49.949153Z",
     "iopub.status.busy": "2025-05-09T22:50:49.948941Z",
     "iopub.status.idle": "2025-05-09T22:50:49.954280Z",
     "shell.execute_reply": "2025-05-09T22:50:49.953801Z",
     "shell.execute_reply.started": "2025-05-09T22:50:49.949138Z"
    }
   },
   "outputs": [],
   "source": [
    "# pub_sub_langgraph_v3_multiple_publishers.py\n",
    "\n",
    "from typing import TypedDict, List, Optional, Annotated, Set, Dict, Any\n",
    "import operator\n",
    "import uuid\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# --- 1. Define Subscriber Interests ---\n",
    "SUBSCRIBER_INTERESTS = {\n",
    "    \"subscriber_alpha\": [\"ALERT\", \"CRITICAL_SENSOR\"],\n",
    "    \"subscriber_beta\": [\"UPDATE\", \"USER_ACTION\", \"GENERAL\"],\n",
    "    \"subscriber_gamma\": [\"ALERT\", \"SYSTEM_HEALTH\", \"STATS\", \"MAINTENANCE\"],\n",
    "    \"subscriber_audit\": [\"USER_ACTION\", \"CRITICAL_SENSOR\", \"SYSTEM_CONFIG_CHANGE\", \"SECURITY_ALERT\"]\n",
    "}\n",
    "\n",
    "# --- 2. Define the State ---\n",
    "class PubSubState(TypedDict):\n",
    "    event_id: str\n",
    "    # initial_event_payload will now contain a 'source_type' key\n",
    "    initial_event_payload: Dict[str, Any] \n",
    "    \n",
    "    # Info about which publisher handled this event (for clarity/logging)\n",
    "    publisher_identity: Optional[str]\n",
    "    \n",
    "    # Standard fields for the published message\n",
    "    published_message_content: Optional[str]\n",
    "    published_message_topics: List[str]\n",
    "    \n",
    "    # Subscriber control flow\n",
    "    subscribers_matched_for_event: List[str] \n",
    "    subscribers_completed_for_event: Set[str] \n",
    "    \n",
    "    subscriber_logs: Annotated[Dict[str, List[str]], operator.ior]\n",
    "\n",
    "\n",
    "# --- Helper to initialize/reset logs for an event ---\n",
    "def get_initial_subscriber_logs_for_event() -> Dict[str, List[str]]:\n",
    "    return {sub_name: [] for sub_name in SUBSCRIBER_INTERESTS.keys()}\n",
    "\n",
    "# --- Utility to reset parts of state for a new event publication ---\n",
    "# def reset_publication_state_fields() -> Dict: ## ERROR\n",
    "#     return {\n",
    "#         \"published_message_content\": None,\n",
    "#         \"published_message_topics\": [],\n",
    "#         \"subscribers_matched_for_event\": [],\n",
    "#         \"subscribers_completed_for_event\": set(),\n",
    "#         \"subscriber_logs\": get_initial_subscriber_logs_for_event()\n",
    "#     }\n",
    "\n",
    "def reset_publication_state_fields() -> Dict:\n",
    "    \"\"\"\n",
    "    Resets state fields that are specific to the subscriber processing loop\n",
    "    for a new event/publication.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        # \"published_message_content\": None, # DO NOT RESET THESE HERE\n",
    "        # \"published_message_topics\": [],    # PUBLISHER SETS THEM\n",
    "        \"subscribers_matched_for_event\": [],  # Reset for the new message\n",
    "        \"subscribers_completed_for_event\": set(), # Reset for the new message\n",
    "        \"subscriber_logs\": get_initial_subscriber_logs_for_event() # Reset for the new message\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6029df02-609e-45ba-833b-9ec2adce0b0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T22:50:51.457313Z",
     "iopub.status.busy": "2025-05-09T22:50:51.457147Z",
     "iopub.status.idle": "2025-05-09T22:50:51.463797Z",
     "shell.execute_reply": "2025-05-09T22:50:51.463348Z",
     "shell.execute_reply.started": "2025-05-09T22:50:51.457301Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- 3. Define Specialized Publisher Node Functions ---\n",
    "\n",
    "def publisher_sensor_events_node(state: PubSubState) -> Dict:\n",
    "    event_id = state[\"event_id\"]\n",
    "    payload = state[\"initial_event_payload\"].get(\"details\", {})\n",
    "    publisher_id = \"SensorPublisher\"\n",
    "    print(f\"\\n--- Publisher: {publisher_id} (Event ID: {event_id}) ---\")\n",
    "    \n",
    "    reading = payload.get(\"reading\", \"N/A\")\n",
    "    unit = payload.get(\"unit\", \"\")\n",
    "    status = payload.get(\"status\", \"NORMAL\").upper()\n",
    "\n",
    "    message_content = f\"Sensor Event: ID {payload.get('sensor_id', 'UnknownSensor')}, Reading {reading}{unit}, Status: {status}.\"\n",
    "    derived_topics = [\"SENSOR_DATA\"]\n",
    "    if status == \"CRITICAL\":\n",
    "        derived_topics.extend([\"CRITICAL_SENSOR\", \"ALERT\"])\n",
    "    elif status == \"WARNING\":\n",
    "        derived_topics.extend([\"WARNING_SENSOR\", \"ALERT\"])\n",
    "    \n",
    "    print(f\"Publishing from {publisher_id}: '{message_content}' with Topics: {derived_topics}\")\n",
    "    \n",
    "    return {\n",
    "        \"publisher_identity\": publisher_id,\n",
    "        \"published_message_content\": message_content,\n",
    "        \"published_message_topics\": derived_topics,\n",
    "        **reset_publication_state_fields() # Reset subscriber tracking for this new message\n",
    "    }\n",
    "\n",
    "def publisher_user_actions_node(state: PubSubState) -> Dict:\n",
    "    event_id = state[\"event_id\"]\n",
    "    payload = state[\"initial_event_payload\"].get(\"details\", {})\n",
    "    publisher_id = \"UserActionPublisher\"\n",
    "    print(f\"\\n--- Publisher: {publisher_id} (Event ID: {event_id}) ---\")\n",
    "\n",
    "    user_id = payload.get(\"user_id\", \"anonymous\")\n",
    "    action = payload.get(\"action\", \"unknown_action\").upper()\n",
    "    resource = payload.get(\"resource\", \"N/A\")\n",
    "\n",
    "    message_content = f\"User Action: User '{user_id}' performed '{action}' on '{resource}'.\"\n",
    "    derived_topics = [\"USER_ACTION\", action] # e.g., USER_ACTION, LOGIN\n",
    "\n",
    "    if \"DELETE\" in action or \"SUSPEND\" in action:\n",
    "        derived_topics.extend([\"CRITICAL_USER_ACTION\", \"ALERT\", \"SECURITY_ALERT\"])\n",
    "    if action == \"CONFIG_CHANGE\" and resource.startswith(\"system\"): # Example\n",
    "        derived_topics.append(\"SYSTEM_CONFIG_CHANGE\")\n",
    "\n",
    "    print(f\"Publishing from {publisher_id}: '{message_content}' with Topics: {derived_topics}\")\n",
    "    \n",
    "    return {\n",
    "        \"publisher_identity\": publisher_id,\n",
    "        \"published_message_content\": message_content,\n",
    "        \"published_message_topics\": derived_topics,\n",
    "        **reset_publication_state_fields()\n",
    "    }\n",
    "\n",
    "def publisher_system_events_node(state: PubSubState) -> Dict:\n",
    "    event_id = state[\"event_id\"]\n",
    "    payload = state[\"initial_event_payload\"].get(\"details\", {})\n",
    "    publisher_id = \"SystemEventPublisher\"\n",
    "    print(f\"\\n--- Publisher: {publisher_id} (Event ID: {event_id}) ---\")\n",
    "\n",
    "    event_name = payload.get(\"event_name\", \"generic_system_event\").upper()\n",
    "    severity = payload.get(\"severity\", \"INFO\").upper()\n",
    "    component = payload.get(\"component\", \"CORE\").upper()\n",
    "\n",
    "    message_content = f\"System Event: '{event_name}' from component '{component}', Severity: {severity}.\"\n",
    "    derived_topics = [\"SYSTEM_EVENT\", f\"SYSTEM_{component}\", f\"SEVERITY_{severity}\"]\n",
    "\n",
    "    if severity in [\"ERROR\", \"FATAL\", \"CRITICAL\"]:\n",
    "        derived_topics.append(\"ALERT\")\n",
    "    if event_name == \"HEALTH_CHECK_FAIL\":\n",
    "        derived_topics.append(\"SYSTEM_HEALTH\")\n",
    "    if \"MAINTENANCE\" in event_name:\n",
    "        derived_topics.append(\"MAINTENANCE\")\n",
    "    if \"STATS_REPORT\" in event_name:\n",
    "        derived_topics.append(\"STATS\")\n",
    "\n",
    "    print(f\"Publishing from {publisher_id}: '{message_content}' with Topics: {derived_topics}\")\n",
    "    \n",
    "    return {\n",
    "        \"publisher_identity\": publisher_id,\n",
    "        \"published_message_content\": message_content,\n",
    "        \"published_message_topics\": derived_topics,\n",
    "        **reset_publication_state_fields()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "362fb9b5-9567-4011-80dc-4e621546dc14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T22:50:52.684038Z",
     "iopub.status.busy": "2025-05-09T22:50:52.683848Z",
     "iopub.status.idle": "2025-05-09T22:50:52.687495Z",
     "shell.execute_reply": "2025-05-09T22:50:52.687051Z",
     "shell.execute_reply.started": "2025-05-09T22:50:52.684025Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- 4. Publisher Router Node ---\n",
    "def route_to_correct_publisher(state: PubSubState) -> str:\n",
    "    \"\"\"\n",
    "    Inspects the initial event payload to determine which publisher logic to use.\n",
    "    The `initial_event_payload` must contain a `source_type` field.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Event Source Router (Selecting Publisher) ---\")\n",
    "    source_type = state[\"initial_event_payload\"].get(\"source_type\", \"UNKNOWN\").upper()\n",
    "    \n",
    "    if source_type == \"SENSOR_EVENT\":\n",
    "        print(\"Routing to SENSOR event publisher.\")\n",
    "        return \"publisher_sensor\"\n",
    "    elif source_type == \"USER_ACTION_EVENT\":\n",
    "        print(\"Routing to USER_ACTION event publisher.\")\n",
    "        return \"publisher_user_action\"\n",
    "    elif source_type == \"SYSTEM_INTERNAL_EVENT\":\n",
    "        print(\"Routing to SYSTEM event publisher.\")\n",
    "        return \"publisher_system\"\n",
    "    else:\n",
    "        print(f\"Warning: Unknown source_type '{source_type}'. Defaulting to system publisher.\")\n",
    "        # Fallback or error handling: could route to a generic/error publisher\n",
    "        return \"publisher_system\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71c516e5-e330-4743-97c6-215f7ee5de19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T22:50:53.779879Z",
     "iopub.status.busy": "2025-05-09T22:50:53.779688Z",
     "iopub.status.idle": "2025-05-09T22:50:53.786396Z",
     "shell.execute_reply": "2025-05-09T22:50:53.785918Z",
     "shell.execute_reply.started": "2025-05-09T22:50:53.779867Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- 5. Subscriber Logic (Router and Individual Subscribers) ---\n",
    "# This part remains largely the same as before.\n",
    "\n",
    "def subscriber_router_node(state: PubSubState) -> Dict:\n",
    "    print(\"\\n--- Subscriber Router Node (Matching Subscribers to Message) ---\")\n",
    "    if not state.get(\"published_message_topics\"): # Should always be set by a publisher\n",
    "        print(\"Error: No message topics found in state for subscriber routing.\")\n",
    "        return {\"subscribers_matched_for_event\": []}\n",
    "\n",
    "    published_topics = state[\"published_message_topics\"]\n",
    "    matched_subscribers = []\n",
    "    for sub_name, interests in SUBSCRIBER_INTERESTS.items():\n",
    "        if any(topic in published_topics for topic in interests):\n",
    "            matched_subscribers.append(sub_name)\n",
    "            \n",
    "    print(f\"Message Topics: {published_topics}\")\n",
    "    print(f\"Subscribers Matched for these topics: {matched_subscribers}\")\n",
    "    return {\"subscribers_matched_for_event\": matched_subscribers}\n",
    "\n",
    "def create_subscriber_node(subscriber_name: str): # Factory remains the same\n",
    "    def subscriber_node_logic(state: PubSubState) -> Dict:\n",
    "        print(f\"\\n--- {subscriber_name.upper()} Node ---\")\n",
    "        message = state[\"published_message_content\"]\n",
    "        topics = state[\"published_message_topics\"]\n",
    "        \n",
    "        log_entry = (f\"{subscriber_name.upper()}: Processed message '{message}' \"\n",
    "                     f\"(Originated from: {state.get('publisher_identity', 'Unknown Publisher')}, Topics: {topics})\")\n",
    "        print(log_entry)\n",
    "        \n",
    "        current_logs_for_subscriber = state[\"subscriber_logs\"].get(subscriber_name, [])\n",
    "        new_log_for_this_subscriber = {\n",
    "            subscriber_name: current_logs_for_subscriber + [log_entry]\n",
    "        }\n",
    "        \n",
    "        updated_completed_set = set(state.get(\"subscribers_completed_for_event\", set()))\n",
    "        updated_completed_set.add(subscriber_name)\n",
    "        \n",
    "        return {\n",
    "            \"subscriber_logs\": new_log_for_this_subscriber, # Merge this dict into state\n",
    "            \"subscribers_completed_for_event\": updated_completed_set\n",
    "        }\n",
    "    return subscriber_node_logic\n",
    "\n",
    "subscriber_alpha_node = create_subscriber_node(\"subscriber_alpha\")\n",
    "subscriber_beta_node = create_subscriber_node(\"subscriber_beta\")\n",
    "subscriber_gamma_node = create_subscriber_node(\"subscriber_gamma\")\n",
    "subscriber_audit_node = create_subscriber_node(\"subscriber_audit\")\n",
    "\n",
    "def final_summary_node(state: PubSubState) -> Dict: # Remains the same\n",
    "    print(\"\\n--- Event Processing Summary ---\")\n",
    "    print(f\"Event ID: {state['event_id']}\")\n",
    "    print(f\"Processed by Publisher: {state.get('publisher_identity', 'N/A')}\")\n",
    "    print(f\"Published Message: {state.get('published_message_content', 'N/A')}\")\n",
    "    print(f\"Message Topics: {state.get('published_message_topics', [])}\")\n",
    "    print(f\"Matched Subscribers: {state.get('subscribers_matched_for_event', [])}\")\n",
    "    print(f\"Completed Subscribers: {state.get('subscribers_completed_for_event', set())}\")\n",
    "    print(\"Subscriber Logs for this event:\")\n",
    "    \n",
    "    sorted_log_keys = sorted(state.get(\"subscriber_logs\", {}).keys())\n",
    "    for sub_name in sorted_log_keys:\n",
    "        logs = state[\"subscriber_logs\"].get(sub_name, [])\n",
    "        if logs:\n",
    "            print(f\"  Logs from {sub_name.upper()}:\")\n",
    "            for log_entry in logs:\n",
    "                processed_part = log_entry.split(': ', 1)[1] if ': ' in log_entry else log_entry\n",
    "                print(f\"    - {processed_part}\")\n",
    "    print(\"---------------------------------\")\n",
    "    return {}\n",
    "\n",
    "def route_to_next_subscriber_or_summary(state: PubSubState) -> str: # Remains the same\n",
    "    matched_subscribers = state.get(\"subscribers_matched_for_event\", [])\n",
    "    completed_subscribers = state.get(\"subscribers_completed_for_event\", set())\n",
    "    \n",
    "    if not matched_subscribers:\n",
    "        print(\"Conditional Subscriber Dispatch: No subscribers matched. Routing to summary.\")\n",
    "        return \"summary\"\n",
    "\n",
    "    for sub_name in matched_subscribers:\n",
    "        if sub_name not in completed_subscribers:\n",
    "            print(f\"Conditional Subscriber Dispatch: Routing to next pending subscriber: {sub_name}\")\n",
    "            return sub_name  \n",
    "            \n",
    "    print(\"Conditional Subscriber Dispatch: All matched subscribers processed. Routing to summary.\")\n",
    "    return \"summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e56ba8e-1ce8-4e09-b814-c0cd1fde29a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T22:50:55.404254Z",
     "iopub.status.busy": "2025-05-09T22:50:55.403881Z",
     "iopub.status.idle": "2025-05-09T22:50:55.415725Z",
     "shell.execute_reply": "2025-05-09T22:50:55.415368Z",
     "shell.execute_reply.started": "2025-05-09T22:50:55.404226Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- 6. Define the Graph Workflow ---\n",
    "workflow = StateGraph(PubSubState)\n",
    "\n",
    "# Add an initial node that doesn't do much, just to kick off the publisher routing\n",
    "# This node could also be used for common pre-processing if needed.\n",
    "def initial_event_intake_node(state: PubSubState) -> Dict:\n",
    "    print(\"\\n--- Initial Event Intake ---\")\n",
    "    # Can set event_id here if not passed in initial state, or other common initializations\n",
    "    # For now, it's mainly a starting point for the conditional publisher routing.\n",
    "    return {\"publisher_identity\": None} # Initialize to ensure key exists\n",
    "\n",
    "workflow.add_node(\"initial_intake\", initial_event_intake_node)\n",
    "\n",
    "# Add specialized publisher nodes\n",
    "workflow.add_node(\"publisher_sensor\", publisher_sensor_events_node)\n",
    "workflow.add_node(\"publisher_user_action\", publisher_user_actions_node)\n",
    "workflow.add_node(\"publisher_system\", publisher_system_events_node)\n",
    "\n",
    "# Add subscriber-side nodes (router, individual subscribers, summary)\n",
    "workflow.add_node(\"subscriber_router\", subscriber_router_node)\n",
    "workflow.add_node(\"subscriber_alpha\", subscriber_alpha_node)\n",
    "workflow.add_node(\"subscriber_beta\", subscriber_beta_node)\n",
    "workflow.add_node(\"subscriber_gamma\", subscriber_gamma_node)\n",
    "workflow.add_node(\"subscriber_audit\", subscriber_audit_node)\n",
    "workflow.add_node(\"summary\", final_summary_node)\n",
    "\n",
    "# --- Define Edges and Control Flow ---\n",
    "workflow.set_entry_point(\"initial_intake\")\n",
    "\n",
    "# Conditional Edges from Initial Intake to specific Publisher Nodes\n",
    "workflow.add_conditional_edges(\n",
    "    \"initial_intake\",\n",
    "    route_to_correct_publisher, # This function returns the name of the next node\n",
    "    { # Map of returned names to actual graph nodes\n",
    "        \"publisher_sensor\": \"publisher_sensor\",\n",
    "        \"publisher_user_action\": \"publisher_user_action\",\n",
    "        \"publisher_system\": \"publisher_system\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# ALL specialized publishers, after doing their work, route to the COMMON subscriber_router\n",
    "workflow.add_edge(\"publisher_sensor\", \"subscriber_router\")\n",
    "workflow.add_edge(\"publisher_user_action\", \"subscriber_router\")\n",
    "workflow.add_edge(\"publisher_system\", \"subscriber_router\")\n",
    "\n",
    "# Conditional Edges from Subscriber Router to specific Subscriber Nodes (same as before)\n",
    "workflow.add_conditional_edges(\n",
    "    \"subscriber_router\",\n",
    "    route_to_next_subscriber_or_summary,\n",
    "    {\n",
    "        \"subscriber_alpha\": \"subscriber_alpha\",\n",
    "        \"subscriber_beta\": \"subscriber_beta\",\n",
    "        \"subscriber_gamma\": \"subscriber_gamma\",\n",
    "        \"subscriber_audit\": \"subscriber_audit\",\n",
    "        \"summary\": \"summary\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# After each subscriber finishes, loop back to subscriber_router (same as before)\n",
    "workflow.add_edge(\"subscriber_alpha\", \"subscriber_router\")\n",
    "workflow.add_edge(\"subscriber_beta\", \"subscriber_router\")\n",
    "workflow.add_edge(\"subscriber_gamma\", \"subscriber_router\")\n",
    "workflow.add_edge(\"subscriber_audit\", \"subscriber_router\")\n",
    "\n",
    "workflow.add_edge(\"summary\", END)\n",
    "\n",
    "# --- 7. Compile the Graph ---\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "974d5ffc-53d7-4e57-b2a4-9f8d6688ced9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T22:50:56.946766Z",
     "iopub.status.busy": "2025-05-09T22:50:56.945908Z",
     "iopub.status.idle": "2025-05-09T22:50:56.953843Z",
     "shell.execute_reply": "2025-05-09T22:50:56.953110Z",
     "shell.execute_reply.started": "2025-05-09T22:50:56.946721Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- 8. Run the Graph with Different Example Events ---\n",
    "def run_event_through_pubsub(event_payload_with_source: dict):\n",
    "    event_id = str(uuid.uuid4()) # Generate a unique ID for each event run\n",
    "    print(f\"\\n\\n<<<<< STARTING NEW EVENT: ID {event_id}, Source Type: {event_payload_with_source.get('source_type', 'N/A')} >>>>>\")\n",
    "    \n",
    "    initial_state_for_run = {\n",
    "        \"event_id\": event_id,\n",
    "        \"initial_event_payload\": event_payload_with_source,\n",
    "        # Other state fields will be populated by the graph nodes\n",
    "    }\n",
    "    \n",
    "    final_node_output = None\n",
    "    for step_output in app.stream(initial_state_for_run):\n",
    "        node_name = list(step_output.keys())[0]\n",
    "        # print(f\"Debug: Output from node: {node_name}\") # Optional: for debugging flow\n",
    "        final_node_output = step_output[node_name] # Keep track of the last state snapshot\n",
    "    \n",
    "    # print(f\"\\n--- Final State for Event {event_id} (after {node_name}) ---\")\n",
    "    # for key, value in final_node_output.items():\n",
    "    # print(f\"  {key}: {value}\") # Can be verbose, summary node already prints key info\n",
    "    print(f\"<<<<< FINISHED EVENT: ID {event_id} >>>>>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a4330abc-1be2-4d7b-a292-1ae720c3a6dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T22:51:00.267138Z",
     "iopub.status.busy": "2025-05-09T22:51:00.266776Z",
     "iopub.status.idle": "2025-05-09T22:51:00.275343Z",
     "shell.execute_reply": "2025-05-09T22:51:00.275003Z",
     "shell.execute_reply.started": "2025-05-09T22:51:00.267109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<<<<< STARTING NEW EVENT: ID 42237c01-d67f-4880-a4a3-1c537496a5c3, Source Type: SENSOR_EVENT >>>>>\n",
      "\n",
      "--- Initial Event Intake ---\n",
      "\n",
      "--- Event Source Router (Selecting Publisher) ---\n",
      "Routing to SENSOR event publisher.\n",
      "\n",
      "--- Publisher: SensorPublisher (Event ID: 42237c01-d67f-4880-a4a3-1c537496a5c3) ---\n",
      "Publishing from SensorPublisher: 'Sensor Event: ID temp_CPU0, Reading 95.5C, Status: CRITICAL.' with Topics: ['SENSOR_DATA', 'CRITICAL_SENSOR', 'ALERT']\n",
      "\n",
      "--- Subscriber Router Node (Matching Subscribers to Message) ---\n",
      "Message Topics: ['SENSOR_DATA', 'CRITICAL_SENSOR', 'ALERT']\n",
      "Subscribers Matched for these topics: ['subscriber_alpha', 'subscriber_gamma', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch: Routing to next pending subscriber: subscriber_alpha\n",
      "\n",
      "--- SUBSCRIBER_ALPHA Node ---\n",
      "SUBSCRIBER_ALPHA: Processed message 'Sensor Event: ID temp_CPU0, Reading 95.5C, Status: CRITICAL.' (Originated from: SensorPublisher, Topics: ['SENSOR_DATA', 'CRITICAL_SENSOR', 'ALERT'])\n",
      "\n",
      "--- Subscriber Router Node (Matching Subscribers to Message) ---\n",
      "Message Topics: ['SENSOR_DATA', 'CRITICAL_SENSOR', 'ALERT']\n",
      "Subscribers Matched for these topics: ['subscriber_alpha', 'subscriber_gamma', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch: Routing to next pending subscriber: subscriber_gamma\n",
      "\n",
      "--- SUBSCRIBER_GAMMA Node ---\n",
      "SUBSCRIBER_GAMMA: Processed message 'Sensor Event: ID temp_CPU0, Reading 95.5C, Status: CRITICAL.' (Originated from: SensorPublisher, Topics: ['SENSOR_DATA', 'CRITICAL_SENSOR', 'ALERT'])\n",
      "\n",
      "--- Subscriber Router Node (Matching Subscribers to Message) ---\n",
      "Message Topics: ['SENSOR_DATA', 'CRITICAL_SENSOR', 'ALERT']\n",
      "Subscribers Matched for these topics: ['subscriber_alpha', 'subscriber_gamma', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch: Routing to next pending subscriber: subscriber_audit\n",
      "\n",
      "--- SUBSCRIBER_AUDIT Node ---\n",
      "SUBSCRIBER_AUDIT: Processed message 'Sensor Event: ID temp_CPU0, Reading 95.5C, Status: CRITICAL.' (Originated from: SensorPublisher, Topics: ['SENSOR_DATA', 'CRITICAL_SENSOR', 'ALERT'])\n",
      "\n",
      "--- Subscriber Router Node (Matching Subscribers to Message) ---\n",
      "Message Topics: ['SENSOR_DATA', 'CRITICAL_SENSOR', 'ALERT']\n",
      "Subscribers Matched for these topics: ['subscriber_alpha', 'subscriber_gamma', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch: All matched subscribers processed. Routing to summary.\n",
      "\n",
      "--- Event Processing Summary ---\n",
      "Event ID: 42237c01-d67f-4880-a4a3-1c537496a5c3\n",
      "Processed by Publisher: SensorPublisher\n",
      "Published Message: Sensor Event: ID temp_CPU0, Reading 95.5C, Status: CRITICAL.\n",
      "Message Topics: ['SENSOR_DATA', 'CRITICAL_SENSOR', 'ALERT']\n",
      "Matched Subscribers: ['subscriber_alpha', 'subscriber_gamma', 'subscriber_audit']\n",
      "Completed Subscribers: {'subscriber_alpha', 'subscriber_gamma', 'subscriber_audit'}\n",
      "Subscriber Logs for this event:\n",
      "  Logs from SUBSCRIBER_ALPHA:\n",
      "    - Processed message 'Sensor Event: ID temp_CPU0, Reading 95.5C, Status: CRITICAL.' (Originated from: SensorPublisher, Topics: ['SENSOR_DATA', 'CRITICAL_SENSOR', 'ALERT'])\n",
      "  Logs from SUBSCRIBER_AUDIT:\n",
      "    - Processed message 'Sensor Event: ID temp_CPU0, Reading 95.5C, Status: CRITICAL.' (Originated from: SensorPublisher, Topics: ['SENSOR_DATA', 'CRITICAL_SENSOR', 'ALERT'])\n",
      "  Logs from SUBSCRIBER_GAMMA:\n",
      "    - Processed message 'Sensor Event: ID temp_CPU0, Reading 95.5C, Status: CRITICAL.' (Originated from: SensorPublisher, Topics: ['SENSOR_DATA', 'CRITICAL_SENSOR', 'ALERT'])\n",
      "---------------------------------\n",
      "<<<<< FINISHED EVENT: ID 42237c01-d67f-4880-a4a3-1c537496a5c3 >>>>>\n"
     ]
    }
   ],
   "source": [
    "# Example Events:\n",
    "event_sensor_critical = {\n",
    "    \"source_type\": \"SENSOR_EVENT\",\n",
    "    \"details\": {\"sensor_id\": \"temp_CPU0\", \"reading\": 95.5, \"unit\": \"C\", \"status\": \"CRITICAL\"}\n",
    "}\n",
    "run_event_through_pubsub(event_sensor_critical) # Expect Alpha, Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "11ff45c0-ee21-49f4-96fc-fae34c6faa38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T22:54:12.585740Z",
     "iopub.status.busy": "2025-05-09T22:54:12.585462Z",
     "iopub.status.idle": "2025-05-09T22:54:12.593210Z",
     "shell.execute_reply": "2025-05-09T22:54:12.592816Z",
     "shell.execute_reply.started": "2025-05-09T22:54:12.585718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<<<<< STARTING NEW EVENT: ID 5228f7fd-ce96-4939-b0d4-25de4f012dd3, Source Type: USER_ACTION_EVENT >>>>>\n",
      "\n",
      "--- Initial Event Intake ---\n",
      "\n",
      "--- Event Source Router (Selecting Publisher) ---\n",
      "Routing to USER_ACTION event publisher.\n",
      "\n",
      "--- Publisher: UserActionPublisher (Event ID: 5228f7fd-ce96-4939-b0d4-25de4f012dd3) ---\n",
      "Publishing from UserActionPublisher: 'User Action: User 'operator01' performed 'DELETE_CRITICAL_RESOURCE' on 'db_master_table'.' with Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT']\n",
      "\n",
      "--- Subscriber Router Node (Matching Subscribers to Message) ---\n",
      "Message Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT']\n",
      "Subscribers Matched for these topics: ['subscriber_alpha', 'subscriber_beta', 'subscriber_gamma', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch: Routing to next pending subscriber: subscriber_alpha\n",
      "\n",
      "--- SUBSCRIBER_ALPHA Node ---\n",
      "SUBSCRIBER_ALPHA: Processed message 'User Action: User 'operator01' performed 'DELETE_CRITICAL_RESOURCE' on 'db_master_table'.' (Originated from: UserActionPublisher, Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT'])\n",
      "\n",
      "--- Subscriber Router Node (Matching Subscribers to Message) ---\n",
      "Message Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT']\n",
      "Subscribers Matched for these topics: ['subscriber_alpha', 'subscriber_beta', 'subscriber_gamma', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch: Routing to next pending subscriber: subscriber_beta\n",
      "\n",
      "--- SUBSCRIBER_BETA Node ---\n",
      "SUBSCRIBER_BETA: Processed message 'User Action: User 'operator01' performed 'DELETE_CRITICAL_RESOURCE' on 'db_master_table'.' (Originated from: UserActionPublisher, Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT'])\n",
      "\n",
      "--- Subscriber Router Node (Matching Subscribers to Message) ---\n",
      "Message Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT']\n",
      "Subscribers Matched for these topics: ['subscriber_alpha', 'subscriber_beta', 'subscriber_gamma', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch: Routing to next pending subscriber: subscriber_gamma\n",
      "\n",
      "--- SUBSCRIBER_GAMMA Node ---\n",
      "SUBSCRIBER_GAMMA: Processed message 'User Action: User 'operator01' performed 'DELETE_CRITICAL_RESOURCE' on 'db_master_table'.' (Originated from: UserActionPublisher, Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT'])\n",
      "\n",
      "--- Subscriber Router Node (Matching Subscribers to Message) ---\n",
      "Message Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT']\n",
      "Subscribers Matched for these topics: ['subscriber_alpha', 'subscriber_beta', 'subscriber_gamma', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch: Routing to next pending subscriber: subscriber_audit\n",
      "\n",
      "--- SUBSCRIBER_AUDIT Node ---\n",
      "SUBSCRIBER_AUDIT: Processed message 'User Action: User 'operator01' performed 'DELETE_CRITICAL_RESOURCE' on 'db_master_table'.' (Originated from: UserActionPublisher, Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT'])\n",
      "\n",
      "--- Subscriber Router Node (Matching Subscribers to Message) ---\n",
      "Message Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT']\n",
      "Subscribers Matched for these topics: ['subscriber_alpha', 'subscriber_beta', 'subscriber_gamma', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch: All matched subscribers processed. Routing to summary.\n",
      "\n",
      "--- Event Processing Summary ---\n",
      "Event ID: 5228f7fd-ce96-4939-b0d4-25de4f012dd3\n",
      "Processed by Publisher: UserActionPublisher\n",
      "Published Message: User Action: User 'operator01' performed 'DELETE_CRITICAL_RESOURCE' on 'db_master_table'.\n",
      "Message Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT']\n",
      "Matched Subscribers: ['subscriber_alpha', 'subscriber_beta', 'subscriber_gamma', 'subscriber_audit']\n",
      "Completed Subscribers: {'subscriber_alpha', 'subscriber_audit', 'subscriber_gamma', 'subscriber_beta'}\n",
      "Subscriber Logs for this event:\n",
      "  Logs from SUBSCRIBER_ALPHA:\n",
      "    - Processed message 'User Action: User 'operator01' performed 'DELETE_CRITICAL_RESOURCE' on 'db_master_table'.' (Originated from: UserActionPublisher, Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT'])\n",
      "  Logs from SUBSCRIBER_AUDIT:\n",
      "    - Processed message 'User Action: User 'operator01' performed 'DELETE_CRITICAL_RESOURCE' on 'db_master_table'.' (Originated from: UserActionPublisher, Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT'])\n",
      "  Logs from SUBSCRIBER_BETA:\n",
      "    - Processed message 'User Action: User 'operator01' performed 'DELETE_CRITICAL_RESOURCE' on 'db_master_table'.' (Originated from: UserActionPublisher, Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT'])\n",
      "  Logs from SUBSCRIBER_GAMMA:\n",
      "    - Processed message 'User Action: User 'operator01' performed 'DELETE_CRITICAL_RESOURCE' on 'db_master_table'.' (Originated from: UserActionPublisher, Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT'])\n",
      "---------------------------------\n",
      "<<<<< FINISHED EVENT: ID 5228f7fd-ce96-4939-b0d4-25de4f012dd3 >>>>>\n"
     ]
    }
   ],
   "source": [
    "event_user_delete = {\n",
    "    \"source_type\": \"USER_ACTION_EVENT\",\n",
    "    \"details\": {\"user_id\": \"operator01\", \"action\": \"DELETE_CRITICAL_RESOURCE\", \"resource\": \"db_master_table\"}\n",
    "}\n",
    "run_event_through_pubsub(event_user_delete) # Expect Beta, Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "652d44e4-8d93-45f7-85a9-74daa5b4cbc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T22:57:03.807375Z",
     "iopub.status.busy": "2025-05-09T22:57:03.806704Z",
     "iopub.status.idle": "2025-05-09T22:57:03.812779Z",
     "shell.execute_reply": "2025-05-09T22:57:03.812440Z",
     "shell.execute_reply.started": "2025-05-09T22:57:03.807353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<<<<< STARTING NEW EVENT: ID 5393cdc4-b982-4417-9c88-473e42cbe954, Source Type: SYSTEM_INTERNAL_EVENT >>>>>\n",
      "\n",
      "--- Initial Event Intake ---\n",
      "\n",
      "--- Event Source Router (Selecting Publisher) ---\n",
      "Routing to SYSTEM event publisher.\n",
      "\n",
      "--- Publisher: SystemEventPublisher (Event ID: 5393cdc4-b982-4417-9c88-473e42cbe954) ---\n",
      "Publishing from SystemEventPublisher: 'System Event: 'SCHEDULED_MAINTENANCE_START' from component 'API_GATEWAY', Severity: INFO.' with Topics: ['SYSTEM_EVENT', 'SYSTEM_API_GATEWAY', 'SEVERITY_INFO', 'MAINTENANCE']\n",
      "\n",
      "--- Subscriber Router Node (Matching Subscribers to Message) ---\n",
      "Message Topics: ['SYSTEM_EVENT', 'SYSTEM_API_GATEWAY', 'SEVERITY_INFO', 'MAINTENANCE']\n",
      "Subscribers Matched for these topics: ['subscriber_gamma']\n",
      "Conditional Subscriber Dispatch: Routing to next pending subscriber: subscriber_gamma\n",
      "\n",
      "--- SUBSCRIBER_GAMMA Node ---\n",
      "SUBSCRIBER_GAMMA: Processed message 'System Event: 'SCHEDULED_MAINTENANCE_START' from component 'API_GATEWAY', Severity: INFO.' (Originated from: SystemEventPublisher, Topics: ['SYSTEM_EVENT', 'SYSTEM_API_GATEWAY', 'SEVERITY_INFO', 'MAINTENANCE'])\n",
      "\n",
      "--- Subscriber Router Node (Matching Subscribers to Message) ---\n",
      "Message Topics: ['SYSTEM_EVENT', 'SYSTEM_API_GATEWAY', 'SEVERITY_INFO', 'MAINTENANCE']\n",
      "Subscribers Matched for these topics: ['subscriber_gamma']\n",
      "Conditional Subscriber Dispatch: All matched subscribers processed. Routing to summary.\n",
      "\n",
      "--- Event Processing Summary ---\n",
      "Event ID: 5393cdc4-b982-4417-9c88-473e42cbe954\n",
      "Processed by Publisher: SystemEventPublisher\n",
      "Published Message: System Event: 'SCHEDULED_MAINTENANCE_START' from component 'API_GATEWAY', Severity: INFO.\n",
      "Message Topics: ['SYSTEM_EVENT', 'SYSTEM_API_GATEWAY', 'SEVERITY_INFO', 'MAINTENANCE']\n",
      "Matched Subscribers: ['subscriber_gamma']\n",
      "Completed Subscribers: {'subscriber_gamma'}\n",
      "Subscriber Logs for this event:\n",
      "  Logs from SUBSCRIBER_GAMMA:\n",
      "    - Processed message 'System Event: 'SCHEDULED_MAINTENANCE_START' from component 'API_GATEWAY', Severity: INFO.' (Originated from: SystemEventPublisher, Topics: ['SYSTEM_EVENT', 'SYSTEM_API_GATEWAY', 'SEVERITY_INFO', 'MAINTENANCE'])\n",
      "---------------------------------\n",
      "<<<<< FINISHED EVENT: ID 5393cdc4-b982-4417-9c88-473e42cbe954 >>>>>\n"
     ]
    }
   ],
   "source": [
    "event_system_maintenance = {\n",
    "    \"source_type\": \"SYSTEM_INTERNAL_EVENT\",\n",
    "    \"details\": {\"event_name\": \"SCHEDULED_MAINTENANCE_START\", \"component\": \"API_GATEWAY\", \"severity\": \"INFO\"}\n",
    "}\n",
    "run_event_through_pubsub(event_system_maintenance) # Expect Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9039c7ad-78c2-4045-946f-0f89f33bce3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T22:58:06.823321Z",
     "iopub.status.busy": "2025-05-09T22:58:06.822584Z",
     "iopub.status.idle": "2025-05-09T22:58:06.831783Z",
     "shell.execute_reply": "2025-05-09T22:58:06.831069Z",
     "shell.execute_reply.started": "2025-05-09T22:58:06.823269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<<<<< STARTING NEW EVENT: ID 9edd91f4-c04d-48d1-9848-8f5d03c27e22, Source Type: SENSOR_EVENT >>>>>\n",
      "\n",
      "--- Initial Event Intake ---\n",
      "\n",
      "--- Event Source Router (Selecting Publisher) ---\n",
      "Routing to SENSOR event publisher.\n",
      "\n",
      "--- Publisher: SensorPublisher (Event ID: 9edd91f4-c04d-48d1-9848-8f5d03c27e22) ---\n",
      "Publishing from SensorPublisher: 'Sensor Event: ID flow_H2O, Reading 10.2L/min, Status: NORMAL.' with Topics: ['SENSOR_DATA']\n",
      "\n",
      "--- Subscriber Router Node (Matching Subscribers to Message) ---\n",
      "Message Topics: ['SENSOR_DATA']\n",
      "Subscribers Matched for these topics: []\n",
      "Conditional Subscriber Dispatch: No subscribers matched. Routing to summary.\n",
      "\n",
      "--- Event Processing Summary ---\n",
      "Event ID: 9edd91f4-c04d-48d1-9848-8f5d03c27e22\n",
      "Processed by Publisher: SensorPublisher\n",
      "Published Message: Sensor Event: ID flow_H2O, Reading 10.2L/min, Status: NORMAL.\n",
      "Message Topics: ['SENSOR_DATA']\n",
      "Matched Subscribers: []\n",
      "Completed Subscribers: set()\n",
      "Subscriber Logs for this event:\n",
      "---------------------------------\n",
      "<<<<< FINISHED EVENT: ID 9edd91f4-c04d-48d1-9848-8f5d03c27e22 >>>>>\n"
     ]
    }
   ],
   "source": [
    "event_sensor_normal = {\n",
    "    \"source_type\": \"SENSOR_EVENT\",\n",
    "    \"details\": {\"sensor_id\": \"flow_H2O\", \"reading\": 10.2, \"unit\": \"L/min\", \"status\": \"NORMAL\"}\n",
    "}\n",
    "run_event_through_pubsub(event_sensor_normal) # May not trigger high-alert subscribers directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5ed1bd6d-3ac9-46b7-9830-c889128c5b9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T22:59:05.673317Z",
     "iopub.status.busy": "2025-05-09T22:59:05.672225Z",
     "iopub.status.idle": "2025-05-09T22:59:05.679249Z",
     "shell.execute_reply": "2025-05-09T22:59:05.678969Z",
     "shell.execute_reply.started": "2025-05-09T22:59:05.673221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<<<<< STARTING NEW EVENT: ID 16f03159-db30-473e-845c-dc6dfc61691c, Source Type: USER_ACTION_EVENT >>>>>\n",
      "\n",
      "--- Initial Event Intake ---\n",
      "\n",
      "--- Event Source Router (Selecting Publisher) ---\n",
      "Routing to USER_ACTION event publisher.\n",
      "\n",
      "--- Publisher: UserActionPublisher (Event ID: 16f03159-db30-473e-845c-dc6dfc61691c) ---\n",
      "Publishing from UserActionPublisher: 'User Action: User 'jane.doe' performed 'UPDATE_PROFILE' on 'user_profile_jane.doe'.' with Topics: ['USER_ACTION', 'UPDATE_PROFILE']\n",
      "\n",
      "--- Subscriber Router Node (Matching Subscribers to Message) ---\n",
      "Message Topics: ['USER_ACTION', 'UPDATE_PROFILE']\n",
      "Subscribers Matched for these topics: ['subscriber_beta', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch: Routing to next pending subscriber: subscriber_beta\n",
      "\n",
      "--- SUBSCRIBER_BETA Node ---\n",
      "SUBSCRIBER_BETA: Processed message 'User Action: User 'jane.doe' performed 'UPDATE_PROFILE' on 'user_profile_jane.doe'.' (Originated from: UserActionPublisher, Topics: ['USER_ACTION', 'UPDATE_PROFILE'])\n",
      "\n",
      "--- Subscriber Router Node (Matching Subscribers to Message) ---\n",
      "Message Topics: ['USER_ACTION', 'UPDATE_PROFILE']\n",
      "Subscribers Matched for these topics: ['subscriber_beta', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch: Routing to next pending subscriber: subscriber_audit\n",
      "\n",
      "--- SUBSCRIBER_AUDIT Node ---\n",
      "SUBSCRIBER_AUDIT: Processed message 'User Action: User 'jane.doe' performed 'UPDATE_PROFILE' on 'user_profile_jane.doe'.' (Originated from: UserActionPublisher, Topics: ['USER_ACTION', 'UPDATE_PROFILE'])\n",
      "\n",
      "--- Subscriber Router Node (Matching Subscribers to Message) ---\n",
      "Message Topics: ['USER_ACTION', 'UPDATE_PROFILE']\n",
      "Subscribers Matched for these topics: ['subscriber_beta', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch: All matched subscribers processed. Routing to summary.\n",
      "\n",
      "--- Event Processing Summary ---\n",
      "Event ID: 16f03159-db30-473e-845c-dc6dfc61691c\n",
      "Processed by Publisher: UserActionPublisher\n",
      "Published Message: User Action: User 'jane.doe' performed 'UPDATE_PROFILE' on 'user_profile_jane.doe'.\n",
      "Message Topics: ['USER_ACTION', 'UPDATE_PROFILE']\n",
      "Matched Subscribers: ['subscriber_beta', 'subscriber_audit']\n",
      "Completed Subscribers: {'subscriber_audit', 'subscriber_beta'}\n",
      "Subscriber Logs for this event:\n",
      "  Logs from SUBSCRIBER_AUDIT:\n",
      "    - Processed message 'User Action: User 'jane.doe' performed 'UPDATE_PROFILE' on 'user_profile_jane.doe'.' (Originated from: UserActionPublisher, Topics: ['USER_ACTION', 'UPDATE_PROFILE'])\n",
      "  Logs from SUBSCRIBER_BETA:\n",
      "    - Processed message 'User Action: User 'jane.doe' performed 'UPDATE_PROFILE' on 'user_profile_jane.doe'.' (Originated from: UserActionPublisher, Topics: ['USER_ACTION', 'UPDATE_PROFILE'])\n",
      "---------------------------------\n",
      "<<<<< FINISHED EVENT: ID 16f03159-db30-473e-845c-dc6dfc61691c >>>>>\n"
     ]
    }
   ],
   "source": [
    "event_user_update = {\n",
    "    \"source_type\": \"USER_ACTION_EVENT\",\n",
    "    \"details\": {\"user_id\": \"jane.doe\", \"action\": \"UPDATE_PROFILE\", \"resource\": \"user_profile_jane.doe\"}\n",
    "}\n",
    "run_event_through_pubsub(event_user_update) # Expect Beta, Audit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635e7d9c-2837-4237-a069-041da91f3905",
   "metadata": {},
   "source": [
    "# v4 + multiple input messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47953f5c-f1f6-45c3-9475-928f19584477",
   "metadata": {},
   "source": [
    "The Pub-Sub is never about a single message. It is always about **a lot of messages**, right?\n",
    "\n",
    "Okay, let's refactor the Pub-Sub system to handle a batch of messages. The core idea will be to introduce a loop within the LangGraph execution flow. The graph will take a list of initial event payloads, process them one by one through the existing publisher/subscriber logic, and aggregate the results.\n",
    "\n",
    "**Key Changes:**\n",
    "\n",
    "1.  **State Modification (`BatchPubSubState`):**\n",
    "    *   `initial_batch_of_events`: A list of the raw event payloads to be processed.\n",
    "    *   `current_event_index`: To keep track of which event in the batch is currently being processed.\n",
    "    *   `current_event_id`, `current_event_payload`: To hold the data for the single event currently flowing through the individual pub-sub logic.\n",
    "    *   `processed_event_summaries`: A list to store a summary/result from each event processed in the batch.\n",
    "    *   The existing fields (like `publisher_identity`, `published_message_content`, `subscriber_logs`) will be reused for each event in the batch.\n",
    "\n",
    "2.  **New Batch Control Nodes:**\n",
    "    *   `batch_initializer_node`: Sets up the batch processing (e.g., `current_event_index = 0`).\n",
    "    *   `select_next_event_from_batch_node`: Picks the event at `current_event_index` from the batch, populates `current_event_id` and `current_event_payload`, and **crucially resets the per-event state fields** (like `published_message_content`, `subscribers_matched_for_event`, `subscriber_logs`) to ensure a clean slate for each event.\n",
    "    *   `aggregate_event_result_node`: After an event is fully processed by its subscribers, this node will take the relevant information from the state (e.g., the final state of `subscriber_logs` for that event, `published_message_content`) and append it to `processed_event_summaries`. It then increments `current_event_index`.\n",
    "    *   `batch_finalization_node`: A terminal node that can print a summary of the entire batch processing.\n",
    "\n",
    "3.  **Conditional Routing for the Batch Loop:**\n",
    "    *   After `aggregate_event_result_node`, a conditional edge will check if `current_event_index < len(initial_batch_of_events)`.\n",
    "        *   If true, it routes back to `select_next_event_from_batch_node`.\n",
    "        *   If false, it routes to `batch_finalization_node` (or `END`).\n",
    "\n",
    "4.  **Adaptation of Existing Nodes:**\n",
    "    *   Publisher nodes will now use `state[\"current_event_payload\"]` to get the details for the event they are publishing.\n",
    "    *   The `reset_publication_state_fields()` logic is now centralized in `select_next_event_from_batch_node`.\n",
    "\n",
    "\n",
    "\n",
    "This version introduces an internal loop to process a batch of messages. Each message in the batch goes through its own publication and subscriber matching cycle. The results are collected, and the graph terminates after all messages in the input batch have been processed. This makes the LangGraph system itself responsible for iterating through the \"simultaneously published\" messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6750cb00-c1d8-495d-a032-f53e132b237b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T23:22:40.437083Z",
     "iopub.status.busy": "2025-05-09T23:22:40.436584Z",
     "iopub.status.idle": "2025-05-09T23:22:40.475065Z",
     "shell.execute_reply": "2025-05-09T23:22:40.474598Z",
     "shell.execute_reply.started": "2025-05-09T23:22:40.437045Z"
    }
   },
   "outputs": [],
   "source": [
    "# pub_sub_langgraph_v4_batch_processing_FIXED.py\n",
    "\n",
    "from typing import TypedDict, List, Optional, Annotated, Set, Dict, Any\n",
    "import operator\n",
    "import uuid\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# --- 1. Define Subscriber Interests (remains the same) ---\n",
    "SUBSCRIBER_INTERESTS = {\n",
    "    \"subscriber_alpha\": [\"ALERT\", \"CRITICAL_SENSOR\"],\n",
    "    \"subscriber_beta\": [\"UPDATE\", \"USER_ACTION\", \"GENERAL\"],\n",
    "    \"subscriber_gamma\": [\"ALERT\", \"SYSTEM_HEALTH\", \"STATS\", \"MAINTENANCE\"],\n",
    "    \"subscriber_audit\": [\"USER_ACTION\", \"CRITICAL_SENSOR\", \"SYSTEM_CONFIG_CHANGE\", \"SECURITY_ALERT\"]\n",
    "}\n",
    "\n",
    "# --- 2. Define the State for Batch Processing (remains the same) ---\n",
    "class EventSummary(TypedDict):\n",
    "    event_id: str\n",
    "    original_payload: Dict[str, Any]\n",
    "    publisher_identity: Optional[str]\n",
    "    published_message_content: Optional[str]\n",
    "    published_message_topics: List[str]\n",
    "    matched_subscribers: List[str]\n",
    "    completed_subscribers: Set[str]\n",
    "    subscriber_logs: Dict[str, List[str]]\n",
    "\n",
    "class BatchPubSubState(TypedDict):\n",
    "    initial_batch_of_events: List[Dict[str, Any]]\n",
    "    current_event_index: int\n",
    "    current_event_id: Optional[str]\n",
    "    current_event_payload: Optional[Dict[str, Any]]\n",
    "    publisher_identity: Optional[str]\n",
    "    published_message_content: Optional[str]\n",
    "    published_message_topics: List[str]\n",
    "    subscribers_matched_for_event: List[str]\n",
    "    subscribers_completed_for_event: Set[str]\n",
    "    subscriber_logs: Annotated[Dict[str, List[str]], operator.ior]\n",
    "    processed_event_summaries: Annotated[List[EventSummary], operator.add]\n",
    "\n",
    "# --- Helper to initialize/reset logs for an event (remains the same) ---\n",
    "def get_initial_subscriber_logs_for_event() -> Dict[str, List[str]]:\n",
    "    return {sub_name: [] for sub_name in SUBSCRIBER_INTERESTS.keys()}\n",
    "\n",
    "# --- Utility to reset state fields FOR A SINGLE EVENT within the batch (remains the same) ---\n",
    "def reset_fields_for_new_event_in_batch() -> Dict:\n",
    "    return {\n",
    "        \"publisher_identity\": None,\n",
    "        \"published_message_content\": None,\n",
    "        \"published_message_topics\": [],\n",
    "        \"subscribers_matched_for_event\": [],\n",
    "        \"subscribers_completed_for_event\": set(),\n",
    "        \"subscriber_logs\": get_initial_subscriber_logs_for_event(),\n",
    "        \"current_event_id\": None, # Ensure these are reset too\n",
    "        \"current_event_payload\": None\n",
    "    }\n",
    "\n",
    "# --- 3. Batch Control Nodes ---\n",
    "# MODIFIED batch_initializer_node\n",
    "def batch_initializer_node(state: BatchPubSubState) -> Dict:\n",
    "    print(\"\\n--- Batch Initializer Node ---\")\n",
    "    batch_len = len(state.get(\"initial_batch_of_events\", []))\n",
    "    print(f\"Initializing batch processing for {batch_len} events.\")\n",
    "    return {\n",
    "        \"current_event_index\": 0,\n",
    "        \"processed_event_summaries\": []\n",
    "    }\n",
    "\n",
    "# MODIFIED select_next_event_from_batch_node\n",
    "def select_next_event_from_batch_node(state: BatchPubSubState) -> Dict:\n",
    "    print(\"\\n--- Selecting Next Event from Batch Node ---\")\n",
    "    idx = state[\"current_event_index\"]\n",
    "    batch = state.get(\"initial_batch_of_events\", []) # Default to empty list\n",
    "    \n",
    "    # Always reset per-event fields. If no event is selected, they remain reset.\n",
    "    update_dict = reset_fields_for_new_event_in_batch()\n",
    "\n",
    "    if idx >= len(batch):\n",
    "        print(f\"select_next_event: Index {idx} is out of bounds for batch size {len(batch)}. No event selected.\")\n",
    "        # current_event_payload remains None from reset_fields...\n",
    "        return update_dict \n",
    "    \n",
    "    current_event_raw_payload = batch[idx]\n",
    "    event_id = current_event_raw_payload.get(\"event_id\", str(uuid.uuid4()))\n",
    "    \n",
    "    print(f\"Processing event {idx + 1}/{len(batch)}: ID {event_id}, Payload: {current_event_raw_payload}\")\n",
    "    \n",
    "    update_dict.update({\n",
    "        \"current_event_id\": event_id,\n",
    "        \"current_event_payload\": current_event_raw_payload,\n",
    "    })\n",
    "    return update_dict\n",
    "\n",
    "# aggregate_event_result_node (remains mostly the same, minor safety for Nones)\n",
    "def aggregate_event_result_node(state: BatchPubSubState) -> Dict:\n",
    "    print(\"\\n--- Aggregating Event Result Node ---\")\n",
    "    \n",
    "    # This node is now only called if an event was actually processed.\n",
    "    # However, good practice to use .get with defaults.\n",
    "    event_summary: EventSummary = {\n",
    "        \"event_id\": state.get(\"current_event_id\", \"N/A_Error\"),\n",
    "        \"original_payload\": state.get(\"current_event_payload\", {}), # Should be set if we got here via event processing\n",
    "        \"publisher_identity\": state.get(\"publisher_identity\"),\n",
    "        \"published_message_content\": state.get(\"published_message_content\"),\n",
    "        \"published_message_topics\": list(state.get(\"published_message_topics\", [])),\n",
    "        \"matched_subscribers\": list(state.get(\"subscribers_matched_for_event\", [])),\n",
    "        \"completed_subscribers\": set(state.get(\"subscribers_completed_for_event\", set())),\n",
    "        \"subscriber_logs\": dict(state.get(\"subscriber_logs\", {}))\n",
    "    }\n",
    "    \n",
    "    next_index = state[\"current_event_index\"] + 1 # Increment index for the *next* potential event\n",
    "    print(f\"Finished processing event ID {event_summary['event_id']}. Aggregated its summary. Next index to try: {next_index}.\")\n",
    "    \n",
    "    return {\n",
    "        \"processed_event_summaries\": [event_summary],\n",
    "        \"current_event_index\": next_index\n",
    "    }\n",
    "\n",
    "# batch_finalization_node (remains the same)\n",
    "def batch_finalization_node(state: BatchPubSubState) -> Dict:\n",
    "    print(\"\\n--- Batch Finalization Node ---\")\n",
    "    summaries = state.get(\"processed_event_summaries\", [])\n",
    "    print(f\"Batch processing complete. Total events processed: {len(summaries)}\")\n",
    "    for i, summary in enumerate(summaries):\n",
    "        print(f\"\\n  Summary for Batch Event {i+1} (Original ID: {summary['event_id']}):\")\n",
    "        print(f\"    Published by: {summary['publisher_identity']}\")\n",
    "        print(f\"    Message: '{summary['published_message_content']}'\")\n",
    "        print(f\"    Topics: {summary['published_message_topics']}\")\n",
    "        print(f\"    Matched Subscribers: {summary['matched_subscribers']}\")\n",
    "    print(\"--------------------------------------\")\n",
    "    return {}\n",
    "\n",
    "# --- 4. Specialized Publisher Nodes (remain the same) ---\n",
    "def publisher_sensor_events_node(state: BatchPubSubState) -> Dict: # ... (no changes)\n",
    "    event_id = state[\"current_event_id\"] \n",
    "    payload_details = state[\"current_event_payload\"].get(\"details\", {}) \n",
    "    publisher_id = \"SensorPublisher\"\n",
    "    print(f\"\\n--- Publisher: {publisher_id} (Current Event ID: {event_id}) ---\")\n",
    "    reading = payload_details.get(\"reading\", \"N/A\")\n",
    "    unit = payload_details.get(\"unit\", \"\")\n",
    "    status = payload_details.get(\"status\", \"NORMAL\").upper()\n",
    "    message_content = f\"Sensor Event: ID {payload_details.get('sensor_id', 'UnknownSensor')}, Reading {reading}{unit}, Status: {status}.\"\n",
    "    derived_topics = [\"SENSOR_DATA\"]\n",
    "    if status == \"CRITICAL\":\n",
    "        derived_topics.extend([\"CRITICAL_SENSOR\", \"ALERT\"])\n",
    "    elif status == \"WARNING\":\n",
    "        derived_topics.extend([\"WARNING_SENSOR\", \"ALERT\"])\n",
    "    print(f\"Publishing from {publisher_id} for Event ID {event_id}: '{message_content}' with Topics: {derived_topics}\")\n",
    "    return { \n",
    "        \"publisher_identity\": publisher_id,\n",
    "        \"published_message_content\": message_content,\n",
    "        \"published_message_topics\": derived_topics,\n",
    "    }\n",
    "def publisher_user_actions_node(state: BatchPubSubState) -> Dict: # ... (no changes)\n",
    "    event_id = state[\"current_event_id\"]\n",
    "    payload_details = state[\"current_event_payload\"].get(\"details\", {})\n",
    "    publisher_id = \"UserActionPublisher\"\n",
    "    print(f\"\\n--- Publisher: {publisher_id} (Current Event ID: {event_id}) ---\")\n",
    "    user_id = payload_details.get(\"user_id\", \"anonymous\")\n",
    "    action = payload_details.get(\"action\", \"unknown_action\").upper()\n",
    "    resource = payload_details.get(\"resource\", \"N/A\")\n",
    "    message_content = f\"User Action: User '{user_id}' performed '{action}' on '{resource}'.\"\n",
    "    derived_topics = [\"USER_ACTION\", action]\n",
    "    if \"DELETE\" in action or \"SUSPEND\" in action:\n",
    "        derived_topics.extend([\"CRITICAL_USER_ACTION\", \"ALERT\", \"SECURITY_ALERT\"])\n",
    "    if action == \"CONFIG_CHANGE\" and resource.startswith(\"system\"):\n",
    "        derived_topics.append(\"SYSTEM_CONFIG_CHANGE\")\n",
    "    print(f\"Publishing from {publisher_id} for Event ID {event_id}: '{message_content}' with Topics: {derived_topics}\")\n",
    "    return {\n",
    "        \"publisher_identity\": publisher_id,\n",
    "        \"published_message_content\": message_content,\n",
    "        \"published_message_topics\": derived_topics,\n",
    "    }\n",
    "def publisher_system_events_node(state: BatchPubSubState) -> Dict: # ... (no changes)\n",
    "    event_id = state[\"current_event_id\"]\n",
    "    payload_details = state[\"current_event_payload\"].get(\"details\", {})\n",
    "    publisher_id = \"SystemEventPublisher\"\n",
    "    print(f\"\\n--- Publisher: {publisher_id} (Current Event ID: {event_id}) ---\")\n",
    "    event_name = payload_details.get(\"event_name\", \"generic_system_event\").upper()\n",
    "    severity = payload_details.get(\"severity\", \"INFO\").upper()\n",
    "    component = payload_details.get(\"component\", \"CORE\").upper()\n",
    "    message_content = f\"System Event: '{event_name}' from component '{component}', Severity: {severity}.\"\n",
    "    derived_topics = [\"SYSTEM_EVENT\", f\"SYSTEM_{component}\", f\"SEVERITY_{severity}\"]\n",
    "    if severity in [\"ERROR\", \"FATAL\", \"CRITICAL\"]:\n",
    "        derived_topics.append(\"ALERT\")\n",
    "    if event_name == \"HEALTH_CHECK_FAIL\":\n",
    "        derived_topics.append(\"SYSTEM_HEALTH\")\n",
    "    if \"MAINTENANCE\" in event_name:\n",
    "        derived_topics.append(\"MAINTENANCE\")\n",
    "    if \"STATS_REPORT\" in event_name:\n",
    "        derived_topics.append(\"STATS\")\n",
    "    print(f\"Publishing from {publisher_id} for Event ID {event_id}: '{message_content}' with Topics: {derived_topics}\")\n",
    "    return {\n",
    "        \"publisher_identity\": publisher_id,\n",
    "        \"published_message_content\": message_content,\n",
    "        \"published_message_topics\": derived_topics,\n",
    "    }\n",
    "\n",
    "# --- 5. Publisher Router Node (route_to_correct_publisher function remains the same) ---\n",
    "def route_to_correct_publisher(state: BatchPubSubState) -> str: # ... (no changes)\n",
    "    print(\"\\n--- Event Source Router (Selecting Publisher for current event in batch) ---\")\n",
    "    source_type = state[\"current_event_payload\"].get(\"source_type\", \"UNKNOWN\").upper()\n",
    "    event_id = state[\"current_event_id\"]\n",
    "    print(f\"Routing Event ID {event_id} (source: {source_type}) to appropriate publisher.\")\n",
    "    if source_type == \"SENSOR_EVENT\":\n",
    "        return \"publisher_sensor\"\n",
    "    elif source_type == \"USER_ACTION_EVENT\":\n",
    "        return \"publisher_user_action\"\n",
    "    elif source_type == \"SYSTEM_INTERNAL_EVENT\":\n",
    "        return \"publisher_system\"\n",
    "    else:\n",
    "        print(f\"Warning: Unknown source_type '{source_type}' for Event ID {event_id}. Defaulting to system publisher.\")\n",
    "        return \"publisher_system\" \n",
    "\n",
    "# --- 6. Subscriber Logic (remain the same) ---\n",
    "def subscriber_router_node(state: BatchPubSubState) -> Dict: # ... (no changes)\n",
    "    event_id = state[\"current_event_id\"]\n",
    "    print(f\"\\n--- Subscriber Router Node (Current Event ID: {event_id}) ---\")\n",
    "    published_topics = state.get(\"published_message_topics\", [])\n",
    "    if not published_topics and not isinstance(published_topics, list):\n",
    "        print(f\"Error for Event ID {event_id}: No message topics found or not a list.\")\n",
    "        return {\"subscribers_matched_for_event\": []}\n",
    "    matched_subscribers = []\n",
    "    for sub_name, interests in SUBSCRIBER_INTERESTS.items():\n",
    "        if any(topic in published_topics for topic in interests):\n",
    "            matched_subscribers.append(sub_name)\n",
    "    print(f\"Event ID {event_id} - Message Topics: {published_topics}, Matched Subscribers: {matched_subscribers}\")\n",
    "    return {\"subscribers_matched_for_event\": matched_subscribers}\n",
    "def create_subscriber_node(subscriber_name: str): # ... (no changes)\n",
    "    def subscriber_node_logic(state: BatchPubSubState) -> Dict:\n",
    "        event_id = state['current_event_id']\n",
    "        print(f\"\\n--- {subscriber_name.upper()} Node (Current Event ID: {event_id}) ---\")\n",
    "        message = state[\"published_message_content\"]\n",
    "        topics = state[\"published_message_topics\"]\n",
    "        log_entry = (f\"{subscriber_name.upper()}: Processed message '{message}' \"\n",
    "                     f\"(Originated from: {state.get('publisher_identity', 'Unknown Publisher')}, Topics: {topics})\")\n",
    "        print(log_entry)\n",
    "        new_log_update_for_this_event = {\n",
    "            subscriber_name: [log_entry] \n",
    "        }\n",
    "        updated_completed_set = set(state.get(\"subscribers_completed_for_event\", set()))\n",
    "        updated_completed_set.add(subscriber_name)\n",
    "        return {\n",
    "            \"subscriber_logs\": new_log_update_for_this_event,\n",
    "            \"subscribers_completed_for_event\": updated_completed_set\n",
    "        }\n",
    "    return subscriber_node_logic\n",
    "subscriber_alpha_node = create_subscriber_node(\"subscriber_alpha\")\n",
    "subscriber_beta_node = create_subscriber_node(\"subscriber_beta\")\n",
    "subscriber_gamma_node = create_subscriber_node(\"subscriber_gamma\")\n",
    "subscriber_audit_node = create_subscriber_node(\"subscriber_audit\")\n",
    "\n",
    "# --- 7. Conditional Logic for Batch and Subscriber Dispatch ---\n",
    "# route_after_event_aggregation (remains the same)\n",
    "def route_after_event_aggregation(state: BatchPubSubState) -> str: # ... (no changes)\n",
    "    idx = state[\"current_event_index\"] \n",
    "    batch_size = len(state.get(\"initial_batch_of_events\", []))\n",
    "    if idx < batch_size:\n",
    "        print(f\"Conditional Batch Route: More events in batch (next index {idx}). Routing to select_next_event.\")\n",
    "        return \"select_next_event\"\n",
    "    else:\n",
    "        print(f\"Conditional Batch Route: All {batch_size} events processed. Routing to batch_finalize.\")\n",
    "        return \"batch_finalize\"\n",
    "# route_to_next_subscriber_or_aggregate (remains the same)\n",
    "def route_to_next_subscriber_or_aggregate(state: BatchPubSubState) -> str: # ... (no changes)\n",
    "    event_id = state['current_event_id']\n",
    "    matched_subscribers = state.get(\"subscribers_matched_for_event\", [])\n",
    "    completed_subscribers = state.get(\"subscribers_completed_for_event\", set())\n",
    "    if not matched_subscribers:\n",
    "        print(f\"Conditional Subscriber Dispatch (Event ID {event_id}): No subscribers matched. Routing to aggregate_result.\")\n",
    "        return \"aggregate_result\"\n",
    "    for sub_name in matched_subscribers:\n",
    "        if sub_name not in completed_subscribers:\n",
    "            print(f\"Conditional Subscriber Dispatch (Event ID {event_id}): Routing to subscriber: {sub_name}\")\n",
    "            return sub_name  \n",
    "    print(f\"Conditional Subscriber Dispatch (Event ID {event_id}): All matched subscribers processed. Routing to aggregate_result.\")\n",
    "    return \"aggregate_result\"\n",
    "\n",
    "# NEW Conditional function after event selection\n",
    "def check_if_event_selected_for_processing(state: BatchPubSubState) -> str:\n",
    "    if state.get(\"current_event_payload\") is not None:\n",
    "        # An event was successfully selected and its payload is in the state\n",
    "        print(\"check_if_event_selected: Event selected. Routing to publisher_router_hub.\")\n",
    "        return \"publisher_router_hub\"\n",
    "    else:\n",
    "        # No event was selected (empty batch from start, or end of batch reached by select_next_event)\n",
    "        print(\"check_if_event_selected: No event selected. Batch processing will be finalized.\")\n",
    "        return \"batch_finalize\"\n",
    "\n",
    "# --- 8. Define the Graph Workflow ---\n",
    "workflow = StateGraph(BatchPubSubState)\n",
    "\n",
    "# Batch control nodes\n",
    "workflow.add_node(\"batch_initialize\", batch_initializer_node)\n",
    "workflow.add_node(\"select_next_event\", select_next_event_from_batch_node)\n",
    "workflow.add_node(\"aggregate_result\", aggregate_event_result_node)\n",
    "workflow.add_node(\"batch_finalize\", batch_finalization_node)\n",
    "\n",
    "# NEW Publisher Router Hub node\n",
    "def publisher_router_hub_node(state: BatchPubSubState) -> Dict:\n",
    "    print(\"\\n--- Publisher Router Hub (Triggering publisher selection) ---\")\n",
    "    return {} # No state change, just a routing point\n",
    "workflow.add_node(\"publisher_router_hub\", publisher_router_hub_node)\n",
    "\n",
    "# Publisher nodes (specialized ones)\n",
    "workflow.add_node(\"publisher_sensor\", publisher_sensor_events_node)\n",
    "workflow.add_node(\"publisher_user_action\", publisher_user_actions_node)\n",
    "workflow.add_node(\"publisher_system\", publisher_system_events_node)\n",
    "\n",
    "# Subscriber-side nodes\n",
    "workflow.add_node(\"subscriber_router\", subscriber_router_node)\n",
    "workflow.add_node(\"subscriber_alpha\", subscriber_alpha_node)\n",
    "workflow.add_node(\"subscriber_beta\", subscriber_beta_node)\n",
    "workflow.add_node(\"subscriber_gamma\", subscriber_gamma_node)\n",
    "workflow.add_node(\"subscriber_audit\", subscriber_audit_node)\n",
    "\n",
    "# --- Define Edges and Control Flow ---\n",
    "workflow.set_entry_point(\"batch_initialize\")\n",
    "workflow.add_edge(\"batch_initialize\", \"select_next_event\")\n",
    "\n",
    "# MODIFIED: Conditional edge after selecting an event\n",
    "workflow.add_conditional_edges(\n",
    "    \"select_next_event\",\n",
    "    check_if_event_selected_for_processing, # NEW conditional function\n",
    "    {\n",
    "        \"publisher_router_hub\": \"publisher_router_hub\", # If event selected, go to hub\n",
    "        \"batch_finalize\": \"batch_finalize\"            # If no event, finalize\n",
    "    }\n",
    ")\n",
    "\n",
    "# MODIFIED: Conditional edge FROM the new hub to correct publisher\n",
    "workflow.add_conditional_edges(\n",
    "    \"publisher_router_hub\", # Source is now the hub\n",
    "    route_to_correct_publisher, # Existing function\n",
    "    {\n",
    "        \"publisher_sensor\": \"publisher_sensor\",\n",
    "        \"publisher_user_action\": \"publisher_user_action\",\n",
    "        \"publisher_system\": \"publisher_system\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# All specialized publishers route to the common subscriber_router (same)\n",
    "workflow.add_edge(\"publisher_sensor\", \"subscriber_router\")\n",
    "workflow.add_edge(\"publisher_user_action\", \"subscriber_router\")\n",
    "workflow.add_edge(\"publisher_system\", \"subscriber_router\")\n",
    "\n",
    "# Subscriber router dispatches (same)\n",
    "workflow.add_conditional_edges(\n",
    "    \"subscriber_router\",\n",
    "    route_to_next_subscriber_or_aggregate,\n",
    "    {\n",
    "        \"subscriber_alpha\": \"subscriber_alpha\",\n",
    "        \"subscriber_beta\": \"subscriber_beta\",\n",
    "        \"subscriber_gamma\": \"subscriber_gamma\",\n",
    "        \"subscriber_audit\": \"subscriber_audit\",\n",
    "        \"aggregate_result\": \"aggregate_result\" \n",
    "    }\n",
    ")\n",
    "\n",
    "# After each subscriber finishes, loop back (same)\n",
    "workflow.add_edge(\"subscriber_alpha\", \"subscriber_router\")\n",
    "workflow.add_edge(\"subscriber_beta\", \"subscriber_router\")\n",
    "workflow.add_edge(\"subscriber_gamma\", \"subscriber_router\")\n",
    "workflow.add_edge(\"subscriber_audit\", \"subscriber_router\")\n",
    "\n",
    "# After an event's result is aggregated, decide if more events in batch or finalize (same)\n",
    "workflow.add_conditional_edges(\n",
    "    \"aggregate_result\",\n",
    "    route_after_event_aggregation,\n",
    "    {\n",
    "        \"select_next_event\": \"select_next_event\", \n",
    "        \"batch_finalize\": \"batch_finalize\"       \n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"batch_finalize\", END)\n",
    "\n",
    "# --- 9. Compile the Graph ---\n",
    "app = workflow.compile()\n",
    "\n",
    "# --- 10. Run the Graph with a Batch of Events (same) ---\n",
    "def run_batch_through_pubsub(batch_of_event_payloads: List[Dict[str, Any]]):\n",
    "    print(f\"\\n\\n<<<<< STARTING NEW BATCH OF {len(batch_of_event_payloads)} EVENTS >>>>>\")\n",
    "    initial_state_for_batch = { \"initial_batch_of_events\": batch_of_event_payloads }\n",
    "    final_graph_state = None\n",
    "    # Added recursion_limit for potentially deep loops with many events/subscribers per event\n",
    "    for step_output in app.stream(initial_state_for_batch, {\"recursion_limit\": 200}):\n",
    "        node_name = list(step_output.keys())[0]\n",
    "        final_graph_state = step_output[node_name] \n",
    "    print(\"\\n--- Final State After Batch Processing (from last node output) ---\")\n",
    "    if final_graph_state:\n",
    "        print(f\"Total unique events processed and summarized: {len(final_graph_state.get('processed_event_summaries', []))}\")\n",
    "    else:\n",
    "        print(\"No final state captured.\")\n",
    "    print(f\"<<<<< FINISHED BATCH PROCESSING >>>>>\")\n",
    "\n",
    "# # Example Batch of Events:\n",
    "# batch_events = [\n",
    "#     { \"event_id\": \"event_001_sensor_critical\", \"source_type\": \"SENSOR_EVENT\", \"details\": {\"sensor_id\": \"temp_CPU0\", \"reading\": 95.5, \"unit\": \"C\", \"status\": \"CRITICAL\"}},\n",
    "#     { \"source_type\": \"USER_ACTION_EVENT\", \"details\": {\"user_id\": \"operator01\", \"action\": \"DELETE_CRITICAL_RESOURCE\", \"resource\": \"db_master_table\"}},\n",
    "#     { \"event_id\": \"event_003_system_maint\", \"source_type\": \"SYSTEM_INTERNAL_EVENT\", \"details\": {\"event_name\": \"SCHEDULED_MAINTENANCE_START\", \"component\": \"API_GATEWAY\", \"severity\": \"INFO\"}},\n",
    "# ]\n",
    "# run_batch_through_pubsub(batch_events)\n",
    "\n",
    "# # Test with an empty batch\n",
    "# print(\"\\n\\n--- TESTING WITH EMPTY BATCH ---\")\n",
    "# run_batch_through_pubsub([])\n",
    "\n",
    "# # Test with a single event batch\n",
    "# print(\"\\n\\n--- TESTING WITH SINGLE EVENT BATCH ---\")\n",
    "# run_batch_through_pubsub([\n",
    "#     {\"source_type\": \"SYSTEM_INTERNAL_EVENT\", \"details\": {\"event_name\": \"STATS_REPORT\", \"component\": \"ANALYTICS\", \"severity\": \"INFO\"}}\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aa7e5ed7-9db8-416e-8878-825dea004e09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T23:22:43.258272Z",
     "iopub.status.busy": "2025-05-09T23:22:43.258111Z",
     "iopub.status.idle": "2025-05-09T23:22:43.262195Z",
     "shell.execute_reply": "2025-05-09T23:22:43.261650Z",
     "shell.execute_reply.started": "2025-05-09T23:22:43.258260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- TESTING WITH EMPTY BATCH ---\n",
      "\n",
      "\n",
      "<<<<< STARTING NEW BATCH OF 0 EVENTS >>>>>\n",
      "\n",
      "--- Batch Initializer Node ---\n",
      "Initializing batch processing for 0 events.\n",
      "\n",
      "--- Selecting Next Event from Batch Node ---\n",
      "select_next_event: Index 0 is out of bounds for batch size 0. No event selected.\n",
      "check_if_event_selected: No event selected. Batch processing will be finalized.\n",
      "\n",
      "--- Batch Finalization Node ---\n",
      "Batch processing complete. Total events processed: 0\n",
      "--------------------------------------\n",
      "\n",
      "--- Final State After Batch Processing (from last node output) ---\n",
      "No final state captured.\n",
      "<<<<< FINISHED BATCH PROCESSING >>>>>\n"
     ]
    }
   ],
   "source": [
    "# Test with an empty batch\n",
    "print(\"\\n\\n--- TESTING WITH EMPTY BATCH ---\")\n",
    "run_batch_through_pubsub([])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e1ad3b5f-df8d-4e01-8296-4ac8239100f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T23:22:46.821011Z",
     "iopub.status.busy": "2025-05-09T23:22:46.820786Z",
     "iopub.status.idle": "2025-05-09T23:22:46.827435Z",
     "shell.execute_reply": "2025-05-09T23:22:46.827008Z",
     "shell.execute_reply.started": "2025-05-09T23:22:46.820993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- TESTING WITH SINGLE EVENT BATCH ---\n",
      "\n",
      "\n",
      "<<<<< STARTING NEW BATCH OF 1 EVENTS >>>>>\n",
      "\n",
      "--- Batch Initializer Node ---\n",
      "Initializing batch processing for 1 events.\n",
      "\n",
      "--- Selecting Next Event from Batch Node ---\n",
      "Processing event 1/1: ID c0cc6f5b-e57a-476d-bca6-a8c8eff9572b, Payload: {'source_type': 'SYSTEM_INTERNAL_EVENT', 'details': {'event_name': 'STATS_REPORT', 'component': 'ANALYTICS', 'severity': 'INFO'}}\n",
      "check_if_event_selected: Event selected. Routing to publisher_router_hub.\n",
      "\n",
      "--- Publisher Router Hub (Triggering publisher selection) ---\n",
      "\n",
      "--- Event Source Router (Selecting Publisher for current event in batch) ---\n",
      "Routing Event ID c0cc6f5b-e57a-476d-bca6-a8c8eff9572b (source: SYSTEM_INTERNAL_EVENT) to appropriate publisher.\n",
      "\n",
      "--- Publisher: SystemEventPublisher (Current Event ID: c0cc6f5b-e57a-476d-bca6-a8c8eff9572b) ---\n",
      "Publishing from SystemEventPublisher for Event ID c0cc6f5b-e57a-476d-bca6-a8c8eff9572b: 'System Event: 'STATS_REPORT' from component 'ANALYTICS', Severity: INFO.' with Topics: ['SYSTEM_EVENT', 'SYSTEM_ANALYTICS', 'SEVERITY_INFO', 'STATS']\n",
      "\n",
      "--- Subscriber Router Node (Current Event ID: c0cc6f5b-e57a-476d-bca6-a8c8eff9572b) ---\n",
      "Event ID c0cc6f5b-e57a-476d-bca6-a8c8eff9572b - Message Topics: ['SYSTEM_EVENT', 'SYSTEM_ANALYTICS', 'SEVERITY_INFO', 'STATS'], Matched Subscribers: ['subscriber_gamma']\n",
      "Conditional Subscriber Dispatch (Event ID c0cc6f5b-e57a-476d-bca6-a8c8eff9572b): Routing to subscriber: subscriber_gamma\n",
      "\n",
      "--- SUBSCRIBER_GAMMA Node (Current Event ID: c0cc6f5b-e57a-476d-bca6-a8c8eff9572b) ---\n",
      "SUBSCRIBER_GAMMA: Processed message 'System Event: 'STATS_REPORT' from component 'ANALYTICS', Severity: INFO.' (Originated from: SystemEventPublisher, Topics: ['SYSTEM_EVENT', 'SYSTEM_ANALYTICS', 'SEVERITY_INFO', 'STATS'])\n",
      "\n",
      "--- Subscriber Router Node (Current Event ID: c0cc6f5b-e57a-476d-bca6-a8c8eff9572b) ---\n",
      "Event ID c0cc6f5b-e57a-476d-bca6-a8c8eff9572b - Message Topics: ['SYSTEM_EVENT', 'SYSTEM_ANALYTICS', 'SEVERITY_INFO', 'STATS'], Matched Subscribers: ['subscriber_gamma']\n",
      "Conditional Subscriber Dispatch (Event ID c0cc6f5b-e57a-476d-bca6-a8c8eff9572b): All matched subscribers processed. Routing to aggregate_result.\n",
      "\n",
      "--- Aggregating Event Result Node ---\n",
      "Finished processing event ID c0cc6f5b-e57a-476d-bca6-a8c8eff9572b. Aggregated its summary. Next index to try: 1.\n",
      "Conditional Batch Route: All 1 events processed. Routing to batch_finalize.\n",
      "\n",
      "--- Batch Finalization Node ---\n",
      "Batch processing complete. Total events processed: 1\n",
      "\n",
      "  Summary for Batch Event 1 (Original ID: c0cc6f5b-e57a-476d-bca6-a8c8eff9572b):\n",
      "    Published by: SystemEventPublisher\n",
      "    Message: 'System Event: 'STATS_REPORT' from component 'ANALYTICS', Severity: INFO.'\n",
      "    Topics: ['SYSTEM_EVENT', 'SYSTEM_ANALYTICS', 'SEVERITY_INFO', 'STATS']\n",
      "    Matched Subscribers: ['subscriber_gamma']\n",
      "--------------------------------------\n",
      "\n",
      "--- Final State After Batch Processing (from last node output) ---\n",
      "No final state captured.\n",
      "<<<<< FINISHED BATCH PROCESSING >>>>>\n"
     ]
    }
   ],
   "source": [
    "# Test with a single event batch\n",
    "print(\"\\n\\n--- TESTING WITH SINGLE EVENT BATCH ---\")\n",
    "run_batch_through_pubsub([\n",
    "{\n",
    "\"source_type\": \"SYSTEM_INTERNAL_EVENT\",\n",
    "\"details\": {\"event_name\": \"STATS_REPORT\", \"component\": \"ANALYTICS\", \"severity\": \"INFO\"}\n",
    "}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a54cfd59-b4e8-4e6c-a173-8fcef83d5fe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T23:22:50.545657Z",
     "iopub.status.busy": "2025-05-09T23:22:50.544208Z",
     "iopub.status.idle": "2025-05-09T23:22:50.561432Z",
     "shell.execute_reply": "2025-05-09T23:22:50.560922Z",
     "shell.execute_reply.started": "2025-05-09T23:22:50.545584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<<<<< STARTING NEW BATCH OF 5 EVENTS >>>>>\n",
      "\n",
      "--- Batch Initializer Node ---\n",
      "Initializing batch processing for 5 events.\n",
      "\n",
      "--- Selecting Next Event from Batch Node ---\n",
      "Processing event 1/5: ID event_001_sensor_critical, Payload: {'event_id': 'event_001_sensor_critical', 'source_type': 'SENSOR_EVENT', 'details': {'sensor_id': 'temp_CPU0', 'reading': 95.5, 'unit': 'C', 'status': 'CRITICAL'}}\n",
      "check_if_event_selected: Event selected. Routing to publisher_router_hub.\n",
      "\n",
      "--- Publisher Router Hub (Triggering publisher selection) ---\n",
      "\n",
      "--- Event Source Router (Selecting Publisher for current event in batch) ---\n",
      "Routing Event ID event_001_sensor_critical (source: SENSOR_EVENT) to appropriate publisher.\n",
      "\n",
      "--- Publisher: SensorPublisher (Current Event ID: event_001_sensor_critical) ---\n",
      "Publishing from SensorPublisher for Event ID event_001_sensor_critical: 'Sensor Event: ID temp_CPU0, Reading 95.5C, Status: CRITICAL.' with Topics: ['SENSOR_DATA', 'CRITICAL_SENSOR', 'ALERT']\n",
      "\n",
      "--- Subscriber Router Node (Current Event ID: event_001_sensor_critical) ---\n",
      "Event ID event_001_sensor_critical - Message Topics: ['SENSOR_DATA', 'CRITICAL_SENSOR', 'ALERT'], Matched Subscribers: ['subscriber_alpha', 'subscriber_gamma', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch (Event ID event_001_sensor_critical): Routing to subscriber: subscriber_alpha\n",
      "\n",
      "--- SUBSCRIBER_ALPHA Node (Current Event ID: event_001_sensor_critical) ---\n",
      "SUBSCRIBER_ALPHA: Processed message 'Sensor Event: ID temp_CPU0, Reading 95.5C, Status: CRITICAL.' (Originated from: SensorPublisher, Topics: ['SENSOR_DATA', 'CRITICAL_SENSOR', 'ALERT'])\n",
      "\n",
      "--- Subscriber Router Node (Current Event ID: event_001_sensor_critical) ---\n",
      "Event ID event_001_sensor_critical - Message Topics: ['SENSOR_DATA', 'CRITICAL_SENSOR', 'ALERT'], Matched Subscribers: ['subscriber_alpha', 'subscriber_gamma', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch (Event ID event_001_sensor_critical): Routing to subscriber: subscriber_gamma\n",
      "\n",
      "--- SUBSCRIBER_GAMMA Node (Current Event ID: event_001_sensor_critical) ---\n",
      "SUBSCRIBER_GAMMA: Processed message 'Sensor Event: ID temp_CPU0, Reading 95.5C, Status: CRITICAL.' (Originated from: SensorPublisher, Topics: ['SENSOR_DATA', 'CRITICAL_SENSOR', 'ALERT'])\n",
      "\n",
      "--- Subscriber Router Node (Current Event ID: event_001_sensor_critical) ---\n",
      "Event ID event_001_sensor_critical - Message Topics: ['SENSOR_DATA', 'CRITICAL_SENSOR', 'ALERT'], Matched Subscribers: ['subscriber_alpha', 'subscriber_gamma', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch (Event ID event_001_sensor_critical): Routing to subscriber: subscriber_audit\n",
      "\n",
      "--- SUBSCRIBER_AUDIT Node (Current Event ID: event_001_sensor_critical) ---\n",
      "SUBSCRIBER_AUDIT: Processed message 'Sensor Event: ID temp_CPU0, Reading 95.5C, Status: CRITICAL.' (Originated from: SensorPublisher, Topics: ['SENSOR_DATA', 'CRITICAL_SENSOR', 'ALERT'])\n",
      "\n",
      "--- Subscriber Router Node (Current Event ID: event_001_sensor_critical) ---\n",
      "Event ID event_001_sensor_critical - Message Topics: ['SENSOR_DATA', 'CRITICAL_SENSOR', 'ALERT'], Matched Subscribers: ['subscriber_alpha', 'subscriber_gamma', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch (Event ID event_001_sensor_critical): All matched subscribers processed. Routing to aggregate_result.\n",
      "\n",
      "--- Aggregating Event Result Node ---\n",
      "Finished processing event ID event_001_sensor_critical. Aggregated its summary. Next index to try: 1.\n",
      "Conditional Batch Route: More events in batch (next index 1). Routing to select_next_event.\n",
      "\n",
      "--- Selecting Next Event from Batch Node ---\n",
      "Processing event 2/5: ID 055b6887-bb0f-4736-ad57-4dbc3cd4482f, Payload: {'source_type': 'USER_ACTION_EVENT', 'details': {'user_id': 'operator01', 'action': 'DELETE_CRITICAL_RESOURCE', 'resource': 'db_master_table'}}\n",
      "check_if_event_selected: Event selected. Routing to publisher_router_hub.\n",
      "\n",
      "--- Publisher Router Hub (Triggering publisher selection) ---\n",
      "\n",
      "--- Event Source Router (Selecting Publisher for current event in batch) ---\n",
      "Routing Event ID 055b6887-bb0f-4736-ad57-4dbc3cd4482f (source: USER_ACTION_EVENT) to appropriate publisher.\n",
      "\n",
      "--- Publisher: UserActionPublisher (Current Event ID: 055b6887-bb0f-4736-ad57-4dbc3cd4482f) ---\n",
      "Publishing from UserActionPublisher for Event ID 055b6887-bb0f-4736-ad57-4dbc3cd4482f: 'User Action: User 'operator01' performed 'DELETE_CRITICAL_RESOURCE' on 'db_master_table'.' with Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT']\n",
      "\n",
      "--- Subscriber Router Node (Current Event ID: 055b6887-bb0f-4736-ad57-4dbc3cd4482f) ---\n",
      "Event ID 055b6887-bb0f-4736-ad57-4dbc3cd4482f - Message Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT'], Matched Subscribers: ['subscriber_alpha', 'subscriber_beta', 'subscriber_gamma', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch (Event ID 055b6887-bb0f-4736-ad57-4dbc3cd4482f): Routing to subscriber: subscriber_alpha\n",
      "\n",
      "--- SUBSCRIBER_ALPHA Node (Current Event ID: 055b6887-bb0f-4736-ad57-4dbc3cd4482f) ---\n",
      "SUBSCRIBER_ALPHA: Processed message 'User Action: User 'operator01' performed 'DELETE_CRITICAL_RESOURCE' on 'db_master_table'.' (Originated from: UserActionPublisher, Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT'])\n",
      "\n",
      "--- Subscriber Router Node (Current Event ID: 055b6887-bb0f-4736-ad57-4dbc3cd4482f) ---\n",
      "Event ID 055b6887-bb0f-4736-ad57-4dbc3cd4482f - Message Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT'], Matched Subscribers: ['subscriber_alpha', 'subscriber_beta', 'subscriber_gamma', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch (Event ID 055b6887-bb0f-4736-ad57-4dbc3cd4482f): Routing to subscriber: subscriber_beta\n",
      "\n",
      "--- SUBSCRIBER_BETA Node (Current Event ID: 055b6887-bb0f-4736-ad57-4dbc3cd4482f) ---\n",
      "SUBSCRIBER_BETA: Processed message 'User Action: User 'operator01' performed 'DELETE_CRITICAL_RESOURCE' on 'db_master_table'.' (Originated from: UserActionPublisher, Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT'])\n",
      "\n",
      "--- Subscriber Router Node (Current Event ID: 055b6887-bb0f-4736-ad57-4dbc3cd4482f) ---\n",
      "Event ID 055b6887-bb0f-4736-ad57-4dbc3cd4482f - Message Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT'], Matched Subscribers: ['subscriber_alpha', 'subscriber_beta', 'subscriber_gamma', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch (Event ID 055b6887-bb0f-4736-ad57-4dbc3cd4482f): Routing to subscriber: subscriber_gamma\n",
      "\n",
      "--- SUBSCRIBER_GAMMA Node (Current Event ID: 055b6887-bb0f-4736-ad57-4dbc3cd4482f) ---\n",
      "SUBSCRIBER_GAMMA: Processed message 'User Action: User 'operator01' performed 'DELETE_CRITICAL_RESOURCE' on 'db_master_table'.' (Originated from: UserActionPublisher, Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT'])\n",
      "\n",
      "--- Subscriber Router Node (Current Event ID: 055b6887-bb0f-4736-ad57-4dbc3cd4482f) ---\n",
      "Event ID 055b6887-bb0f-4736-ad57-4dbc3cd4482f - Message Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT'], Matched Subscribers: ['subscriber_alpha', 'subscriber_beta', 'subscriber_gamma', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch (Event ID 055b6887-bb0f-4736-ad57-4dbc3cd4482f): Routing to subscriber: subscriber_audit\n",
      "\n",
      "--- SUBSCRIBER_AUDIT Node (Current Event ID: 055b6887-bb0f-4736-ad57-4dbc3cd4482f) ---\n",
      "SUBSCRIBER_AUDIT: Processed message 'User Action: User 'operator01' performed 'DELETE_CRITICAL_RESOURCE' on 'db_master_table'.' (Originated from: UserActionPublisher, Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT'])\n",
      "\n",
      "--- Subscriber Router Node (Current Event ID: 055b6887-bb0f-4736-ad57-4dbc3cd4482f) ---\n",
      "Event ID 055b6887-bb0f-4736-ad57-4dbc3cd4482f - Message Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT'], Matched Subscribers: ['subscriber_alpha', 'subscriber_beta', 'subscriber_gamma', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch (Event ID 055b6887-bb0f-4736-ad57-4dbc3cd4482f): All matched subscribers processed. Routing to aggregate_result.\n",
      "\n",
      "--- Aggregating Event Result Node ---\n",
      "Finished processing event ID 055b6887-bb0f-4736-ad57-4dbc3cd4482f. Aggregated its summary. Next index to try: 2.\n",
      "Conditional Batch Route: More events in batch (next index 2). Routing to select_next_event.\n",
      "\n",
      "--- Selecting Next Event from Batch Node ---\n",
      "Processing event 3/5: ID event_003_system_maint, Payload: {'event_id': 'event_003_system_maint', 'source_type': 'SYSTEM_INTERNAL_EVENT', 'details': {'event_name': 'SCHEDULED_MAINTENANCE_START', 'component': 'API_GATEWAY', 'severity': 'INFO'}}\n",
      "check_if_event_selected: Event selected. Routing to publisher_router_hub.\n",
      "\n",
      "--- Publisher Router Hub (Triggering publisher selection) ---\n",
      "\n",
      "--- Event Source Router (Selecting Publisher for current event in batch) ---\n",
      "Routing Event ID event_003_system_maint (source: SYSTEM_INTERNAL_EVENT) to appropriate publisher.\n",
      "\n",
      "--- Publisher: SystemEventPublisher (Current Event ID: event_003_system_maint) ---\n",
      "Publishing from SystemEventPublisher for Event ID event_003_system_maint: 'System Event: 'SCHEDULED_MAINTENANCE_START' from component 'API_GATEWAY', Severity: INFO.' with Topics: ['SYSTEM_EVENT', 'SYSTEM_API_GATEWAY', 'SEVERITY_INFO', 'MAINTENANCE']\n",
      "\n",
      "--- Subscriber Router Node (Current Event ID: event_003_system_maint) ---\n",
      "Event ID event_003_system_maint - Message Topics: ['SYSTEM_EVENT', 'SYSTEM_API_GATEWAY', 'SEVERITY_INFO', 'MAINTENANCE'], Matched Subscribers: ['subscriber_gamma']\n",
      "Conditional Subscriber Dispatch (Event ID event_003_system_maint): Routing to subscriber: subscriber_gamma\n",
      "\n",
      "--- SUBSCRIBER_GAMMA Node (Current Event ID: event_003_system_maint) ---\n",
      "SUBSCRIBER_GAMMA: Processed message 'System Event: 'SCHEDULED_MAINTENANCE_START' from component 'API_GATEWAY', Severity: INFO.' (Originated from: SystemEventPublisher, Topics: ['SYSTEM_EVENT', 'SYSTEM_API_GATEWAY', 'SEVERITY_INFO', 'MAINTENANCE'])\n",
      "\n",
      "--- Subscriber Router Node (Current Event ID: event_003_system_maint) ---\n",
      "Event ID event_003_system_maint - Message Topics: ['SYSTEM_EVENT', 'SYSTEM_API_GATEWAY', 'SEVERITY_INFO', 'MAINTENANCE'], Matched Subscribers: ['subscriber_gamma']\n",
      "Conditional Subscriber Dispatch (Event ID event_003_system_maint): All matched subscribers processed. Routing to aggregate_result.\n",
      "\n",
      "--- Aggregating Event Result Node ---\n",
      "Finished processing event ID event_003_system_maint. Aggregated its summary. Next index to try: 3.\n",
      "Conditional Batch Route: More events in batch (next index 3). Routing to select_next_event.\n",
      "\n",
      "--- Selecting Next Event from Batch Node ---\n",
      "Processing event 4/5: ID becc6fae-2cc8-415a-9338-b449c317e1d5, Payload: {'source_type': 'USER_ACTION_EVENT', 'details': {'user_id': 'jane.doe', 'action': 'UPDATE_PROFILE', 'resource': 'user_profile_jane.doe'}}\n",
      "check_if_event_selected: Event selected. Routing to publisher_router_hub.\n",
      "\n",
      "--- Publisher Router Hub (Triggering publisher selection) ---\n",
      "\n",
      "--- Event Source Router (Selecting Publisher for current event in batch) ---\n",
      "Routing Event ID becc6fae-2cc8-415a-9338-b449c317e1d5 (source: USER_ACTION_EVENT) to appropriate publisher.\n",
      "\n",
      "--- Publisher: UserActionPublisher (Current Event ID: becc6fae-2cc8-415a-9338-b449c317e1d5) ---\n",
      "Publishing from UserActionPublisher for Event ID becc6fae-2cc8-415a-9338-b449c317e1d5: 'User Action: User 'jane.doe' performed 'UPDATE_PROFILE' on 'user_profile_jane.doe'.' with Topics: ['USER_ACTION', 'UPDATE_PROFILE']\n",
      "\n",
      "--- Subscriber Router Node (Current Event ID: becc6fae-2cc8-415a-9338-b449c317e1d5) ---\n",
      "Event ID becc6fae-2cc8-415a-9338-b449c317e1d5 - Message Topics: ['USER_ACTION', 'UPDATE_PROFILE'], Matched Subscribers: ['subscriber_beta', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch (Event ID becc6fae-2cc8-415a-9338-b449c317e1d5): Routing to subscriber: subscriber_beta\n",
      "\n",
      "--- SUBSCRIBER_BETA Node (Current Event ID: becc6fae-2cc8-415a-9338-b449c317e1d5) ---\n",
      "SUBSCRIBER_BETA: Processed message 'User Action: User 'jane.doe' performed 'UPDATE_PROFILE' on 'user_profile_jane.doe'.' (Originated from: UserActionPublisher, Topics: ['USER_ACTION', 'UPDATE_PROFILE'])\n",
      "\n",
      "--- Subscriber Router Node (Current Event ID: becc6fae-2cc8-415a-9338-b449c317e1d5) ---\n",
      "Event ID becc6fae-2cc8-415a-9338-b449c317e1d5 - Message Topics: ['USER_ACTION', 'UPDATE_PROFILE'], Matched Subscribers: ['subscriber_beta', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch (Event ID becc6fae-2cc8-415a-9338-b449c317e1d5): Routing to subscriber: subscriber_audit\n",
      "\n",
      "--- SUBSCRIBER_AUDIT Node (Current Event ID: becc6fae-2cc8-415a-9338-b449c317e1d5) ---\n",
      "SUBSCRIBER_AUDIT: Processed message 'User Action: User 'jane.doe' performed 'UPDATE_PROFILE' on 'user_profile_jane.doe'.' (Originated from: UserActionPublisher, Topics: ['USER_ACTION', 'UPDATE_PROFILE'])\n",
      "\n",
      "--- Subscriber Router Node (Current Event ID: becc6fae-2cc8-415a-9338-b449c317e1d5) ---\n",
      "Event ID becc6fae-2cc8-415a-9338-b449c317e1d5 - Message Topics: ['USER_ACTION', 'UPDATE_PROFILE'], Matched Subscribers: ['subscriber_beta', 'subscriber_audit']\n",
      "Conditional Subscriber Dispatch (Event ID becc6fae-2cc8-415a-9338-b449c317e1d5): All matched subscribers processed. Routing to aggregate_result.\n",
      "\n",
      "--- Aggregating Event Result Node ---\n",
      "Finished processing event ID becc6fae-2cc8-415a-9338-b449c317e1d5. Aggregated its summary. Next index to try: 4.\n",
      "Conditional Batch Route: More events in batch (next index 4). Routing to select_next_event.\n",
      "\n",
      "--- Selecting Next Event from Batch Node ---\n",
      "Processing event 5/5: ID ed75f773-f383-4923-8b67-37ba888aebcf, Payload: {'source_type': 'SENSOR_EVENT', 'details': {'sensor_id': 'humidity_room2', 'reading': 45.0, 'unit': '%', 'status': 'NORMAL'}}\n",
      "check_if_event_selected: Event selected. Routing to publisher_router_hub.\n",
      "\n",
      "--- Publisher Router Hub (Triggering publisher selection) ---\n",
      "\n",
      "--- Event Source Router (Selecting Publisher for current event in batch) ---\n",
      "Routing Event ID ed75f773-f383-4923-8b67-37ba888aebcf (source: SENSOR_EVENT) to appropriate publisher.\n",
      "\n",
      "--- Publisher: SensorPublisher (Current Event ID: ed75f773-f383-4923-8b67-37ba888aebcf) ---\n",
      "Publishing from SensorPublisher for Event ID ed75f773-f383-4923-8b67-37ba888aebcf: 'Sensor Event: ID humidity_room2, Reading 45.0%, Status: NORMAL.' with Topics: ['SENSOR_DATA']\n",
      "\n",
      "--- Subscriber Router Node (Current Event ID: ed75f773-f383-4923-8b67-37ba888aebcf) ---\n",
      "Event ID ed75f773-f383-4923-8b67-37ba888aebcf - Message Topics: ['SENSOR_DATA'], Matched Subscribers: []\n",
      "Conditional Subscriber Dispatch (Event ID ed75f773-f383-4923-8b67-37ba888aebcf): No subscribers matched. Routing to aggregate_result.\n",
      "\n",
      "--- Aggregating Event Result Node ---\n",
      "Finished processing event ID ed75f773-f383-4923-8b67-37ba888aebcf. Aggregated its summary. Next index to try: 5.\n",
      "Conditional Batch Route: All 5 events processed. Routing to batch_finalize.\n",
      "\n",
      "--- Batch Finalization Node ---\n",
      "Batch processing complete. Total events processed: 5\n",
      "\n",
      "  Summary for Batch Event 1 (Original ID: event_001_sensor_critical):\n",
      "    Published by: SensorPublisher\n",
      "    Message: 'Sensor Event: ID temp_CPU0, Reading 95.5C, Status: CRITICAL.'\n",
      "    Topics: ['SENSOR_DATA', 'CRITICAL_SENSOR', 'ALERT']\n",
      "    Matched Subscribers: ['subscriber_alpha', 'subscriber_gamma', 'subscriber_audit']\n",
      "\n",
      "  Summary for Batch Event 2 (Original ID: 055b6887-bb0f-4736-ad57-4dbc3cd4482f):\n",
      "    Published by: UserActionPublisher\n",
      "    Message: 'User Action: User 'operator01' performed 'DELETE_CRITICAL_RESOURCE' on 'db_master_table'.'\n",
      "    Topics: ['USER_ACTION', 'DELETE_CRITICAL_RESOURCE', 'CRITICAL_USER_ACTION', 'ALERT', 'SECURITY_ALERT']\n",
      "    Matched Subscribers: ['subscriber_alpha', 'subscriber_beta', 'subscriber_gamma', 'subscriber_audit']\n",
      "\n",
      "  Summary for Batch Event 3 (Original ID: event_003_system_maint):\n",
      "    Published by: SystemEventPublisher\n",
      "    Message: 'System Event: 'SCHEDULED_MAINTENANCE_START' from component 'API_GATEWAY', Severity: INFO.'\n",
      "    Topics: ['SYSTEM_EVENT', 'SYSTEM_API_GATEWAY', 'SEVERITY_INFO', 'MAINTENANCE']\n",
      "    Matched Subscribers: ['subscriber_gamma']\n",
      "\n",
      "  Summary for Batch Event 4 (Original ID: becc6fae-2cc8-415a-9338-b449c317e1d5):\n",
      "    Published by: UserActionPublisher\n",
      "    Message: 'User Action: User 'jane.doe' performed 'UPDATE_PROFILE' on 'user_profile_jane.doe'.'\n",
      "    Topics: ['USER_ACTION', 'UPDATE_PROFILE']\n",
      "    Matched Subscribers: ['subscriber_beta', 'subscriber_audit']\n",
      "\n",
      "  Summary for Batch Event 5 (Original ID: ed75f773-f383-4923-8b67-37ba888aebcf):\n",
      "    Published by: SensorPublisher\n",
      "    Message: 'Sensor Event: ID humidity_room2, Reading 45.0%, Status: NORMAL.'\n",
      "    Topics: ['SENSOR_DATA']\n",
      "    Matched Subscribers: []\n",
      "--------------------------------------\n",
      "\n",
      "--- Final State After Batch Processing (from last node output) ---\n",
      "No final state captured.\n",
      "<<<<< FINISHED BATCH PROCESSING >>>>>\n"
     ]
    }
   ],
   "source": [
    "# Example Batch of Events:\n",
    "batch_events = [\n",
    "    { \n",
    "        \"event_id\": \"event_001_sensor_critical\", # Optional: pre-assign IDs for traceability\n",
    "        \"source_type\": \"SENSOR_EVENT\",\n",
    "        \"details\": {\"sensor_id\": \"temp_CPU0\", \"reading\": 95.5, \"unit\": \"C\", \"status\": \"CRITICAL\"}\n",
    "    },\n",
    "    { \n",
    "        \"source_type\": \"USER_ACTION_EVENT\", # ID will be auto-generated\n",
    "        \"details\": {\"user_id\": \"operator01\", \"action\": \"DELETE_CRITICAL_RESOURCE\", \"resource\": \"db_master_table\"}\n",
    "    },\n",
    "    { \n",
    "        \"event_id\": \"event_003_system_maint\",\n",
    "        \"source_type\": \"SYSTEM_INTERNAL_EVENT\",\n",
    "        \"details\": {\"event_name\": \"SCHEDULED_MAINTENANCE_START\", \"component\": \"API_GATEWAY\", \"severity\": \"INFO\"}\n",
    "    },\n",
    "    { \n",
    "        \"source_type\": \"USER_ACTION_EVENT\",\n",
    "        \"details\": {\"user_id\": \"jane.doe\", \"action\": \"UPDATE_PROFILE\", \"resource\": \"user_profile_jane.doe\"}\n",
    "    },\n",
    "    { # An event that might not trigger many subscribers\n",
    "        \"source_type\": \"SENSOR_EVENT\",\n",
    "        \"details\": {\"sensor_id\": \"humidity_room2\", \"reading\": 45.0, \"unit\": \"%\", \"status\": \"NORMAL\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "run_batch_through_pubsub(batch_events)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52e6dad-feca-432a-8df8-8044849e30d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
